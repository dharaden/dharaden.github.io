{
  "hash": "c257a61268ef5c136cae06ede53625a9",
  "result": {
    "markdown": "---\ntitle: \"Comparing Means: t-tests\"\nsubtitle: \"PSYC 640 - Fall 2023\"\nauthor: \"Dustin Haraden, PhD\"\nformat: \n  revealjs:\n    multiplex: true\n    slide-number: true\n    incremental: true\n    touch: true\n    code-overflow: wrap\n    theme: dark\nexecute: \n  echo: true\neditor: visual\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Last week\n\n::: nonincremental\n-   Categorical Data analysis with the $\\chi^2$ distribution\n    -   Test of Independence & Goodness of Fit Test\n-   Single Sample $t$-test\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lsr)\n# File management\nlibrary(here)\n# for dplyr, ggplot\nlibrary(tidyverse)\n# Making things look nice\nlibrary(ggpubr)\n#Loading data\nlibrary(rio)\n# Assumption Checks\nlibrary(car)\n\n#Remove Scientific Notation \noptions(scipen=999)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Today...\n\n-   Comparing Means with the $t$-test\n    -   Independent samples\n    -   Paired Samples (probably next class)\n\n------------------------------------------------------------------------\n\n## Comparing Means\n\nCalculated using a t-test. To calculate the t-statistic, you will use this formula:\n\n$$t_{df=N-1} = \\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}$$\n\nThe heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.\n\n------------------------------------------------------------------------\n\n### Load in the dataset from last class\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschool <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/example2-chisq.csv\") %>%  \n  mutate(Score_in_memory_game = as.numeric(Score_in_memory_game))\nschool <- school %>% \n  filter(!is.na(Score_in_memory_game))\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### One-sample *t*-tests vs Z-test\n\n| Parameters                                  | Z-test                    | *t*-test                        |\n|-------------------------------|-------------------|-----------------------|\n| $\\large{\\mu}$                               | known                     | known                           |\n| $\\sigma$                                    | known                     | unknown                         |\n| sem or $\\sigma_M$                           | $\\frac{\\sigma}{\\sqrt{N}}$ | $\\frac{\\hat{\\sigma}}{\\sqrt{N}}$ |\n| Probability distribution                    | standard normal           | $t$                             |\n| DF                                          | none                      | $N-1$                           |\n| Tails                                       | One or two                | One or two                      |\n| Critical value $(\\alpha = .05, two-tailed)$ | 1.96                      | Depends on DF                   |\n\n------------------------------------------------------------------------\n\n### **Assumptions of the one-sample *t*-test**\n\n-   **Normality.** We assume the sampling distribution of the mean is normally distributed. Under what two conditions can we be assured that this is true?\n\n-   **Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say. How can we be safe in this assumption?\n\n------------------------------------------------------------------------\n\n### A brief example - REVIEW\n\nUsing the same Census at School data, we find that New York students who participated in a memory game ( $N = 224$ ) completed the game in an average time of 44.2 seconds ( $s = 15.3$ ). We know that the average US student completed the game in 45.04 seconds. How do our students compare? <br>\n\n<br>\n\n**Hypotheses**\n\n$H_0: \\mu = 45.05$\n\n$H_1: \\mu \\neq 45.05$\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\mu = 45.05$$\n\n$$N = 227$$\n\n$$ \\bar{X} = 44.2 $$\n\n$$ s = 15.3 $$\n\n$$\n\\sigma = Unknown\n$$\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x = school$Score_in_memory_game, \n       mu = 45.05,\n       alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  school$Score_in_memory_game\nt = -0.86545, df = 223, p-value = 0.3877\nalternative hypothesis: true mean is not equal to 45.05\n95 percent confidence interval:\n 42.14729 46.18116\nsample estimates:\nmean of x \n 44.16422 \n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlsr::oneSampleTTest(x = school$Score_in_memory_game,\n                    mu = 45.05, one.sided = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   One sample t-test \n\nData variable:   school$Score_in_memory_game \n\nDescriptive statistics: \n            Score_in_memory_game\n   mean                   44.164\n   std dev.               15.318\n\nHypotheses: \n   null:        population mean equals 45.05 \n   alternative: population mean not equal to 45.05 \n\nTest results: \n   t-statistic:  -0.865 \n   degrees of freedom:  223 \n   p-value:  0.388 \n\nOther information: \n   two-sided 95% confidence interval:  [42.147, 46.181] \n   estimated effect size (Cohen's d):  0.058 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Writing Up a t-test\n\n> \"A one-sample t-test was conducted to determine if the mean \\[variable name\\] differed from a hypothesized population mean of \\[population mean\\]. The sample mean was M = \\[sample mean\\], which was significantly \\[greater than/less than/different from\\] the hypothesized population mean, t(df) = \\[t-value\\], p = \\[p-value\\].\"\n\nA one-sample t-test was conducted to determine if the mean score in a memory game for NY students differed from the US population mean. The sample mean was $M = 44.164$ (SD = 15.32, CI = \\[42.15, 46.18\\]), which was not significantly different from the population mean, $t(223) = -0.87$, $p = 0.388$.\n\n------------------------------------------------------------------------\n\nSingle sample t-tests are not used super often in practice\n\nYou will mainly see them when interpreting effect sizes of coefficients in your model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Load sleep data: https://vincentarelbundock.github.io/Rdatasets/datasets.html\nsleep <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/sleepstudy.csv\")\nmodel = lm(Reaction ~ Days, data = sleep)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Reaction ~ Days, data = sleep)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-110.848  -27.483    1.546   26.142  139.953 \n\nCoefficients:\n            Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)  251.405      6.610  38.033 < 0.0000000000000002 ***\nDays          10.467      1.238   8.454  0.00000000000000989 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47.71 on 178 degrees of freedom\nMultiple R-squared:  0.2865,\tAdjusted R-squared:  0.2825 \nF-statistic: 71.46 on 1 and 178 DF,  p-value: 0.000000000000009894\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Types of t-Tests\n\nSingle Samples t-test\n\nIndependent Samples t-test\n\nPaired Samples t-test\n\n------------------------------------------------------------------------\n\n## Types of t-Tests: Assumptions\n\n~~Single Samples t-test~~\n\nIndependent Samples t-test\n\n::: columns\n::: {.column width=\"50%\"}\n-   Random Sampling\n\n-   Independent observations\n:::\n\n::: {.column width=\"50%\"}\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n:::\n:::\n\nPaired Samples t-test\n\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n\n------------------------------------------------------------------------\n\n## Dataset\n\nMoving forward for today, we will use this dataset\n\n::: nonincremental\n-   100 students from New York\n\n-   100 students from New Mexico\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_school <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/NM-NY_CAS.csv\")\n```\n:::\n\n\n## Normality Assumption\n\n1.  **Check for Normality**: Visualizing data (histograms), Q-Q plots, and statistical tests (Shapiro-Wilk, Anderson-Darling) to assess normality.\n\n2.  **Remedies for Violations**: data transformation or non-parametric alternatives when data is not normally distributed.\n\n------------------------------------------------------------------------\n\n### Normality Assumption - Visualizing\n\nVisualizing Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(as.numeric(state_school$Sleep_Hours_Schoolnight))\n```\n\n::: {.cell-output-display}\n![](07_ComparingMeans_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nLet's make it pretty\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstate_school %>% \n  ggplot(aes(Sleep_Hours_Schoolnight,\n             fill = Region)) +\n  geom_bar(position = \"dodge\")\n```\n\n::: {.cell-output-display}\n![](07_ComparingMeans_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Q-Q Plot\n\nA Q-Q plot is a graphical method for assessing whether a dataset follows a normal distribution. It compares the quantiles of your data to the quantiles of a theoretical normal distribution. If your data follows a normal distribution, the points in the Q-Q plot should form a straight line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqPlot(state_school$Sleep_Hours_Schoolnight)\n```\n\n::: {.cell-output-display}\n![](07_ComparingMeans_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 131   6\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Shapiro-Wilk Test\n\nExamines the Null Hypothesis that the data are normally distributed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(state_school$Sleep_Hours_Schoolnight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  state_school$Sleep_Hours_Schoolnight\nW = 0.95501, p-value = 0.00001511\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Normality Assumption\n\n-   Strict adherence to normality assumptions is not always necessary,\n\n    -   Larger samples bring in Central Limit Theorem\n\n-   However, assessing normality is still a valuable step in understanding distributions and potential impacts on your analyses\n\n------------------------------------------------------------------------\n\n### Failure of Normality Assumptions\n\nWhat can we do if our data violate these normality assumptions?\n\n-   Logarithmic Transformations\n\n-   Square Root Transformations\n\n-   Non-parametric tests\n\n    -   **Mann-Whitney U Test (Wilcoxon Rank-Sum Test):** Used for comparing two independent groups\n\n    <!-- -->\n\n    -   **Wilcoxon Signed-Rank Test:** Used for comparing two paired or matched groups\n\n------------------------------------------------------------------------\n\n## Homogeneity of Variance\n\n1.  **Check for Equality of Variances**: Levene's test to assess if variances are equal between groups\n\n2.  **Remedies for Violations**: Welch's t-test for unequal variances.\n\n------------------------------------------------------------------------\n\n### Levene's Test\n\nThis test is used to examine if the variance is equal across groups. The Null Hypothesis is that the variances are equal\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform Levene's test for equality of variances\nleveneTest(Sleep_Hours_Schoolnight ~ Region, \n           data = state_school)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)\ngroup   1  0.5937  0.442\n      180               \n```\n:::\n:::\n\n\n::: {style=\"font-size: 30px\"}\nLike other tests of significance, Levene's test gets more powerful as sample size increases. So unless your two variances are exactly equal to each other (and if they are, you don't need to do a test), your test will be \"significant\" with a large enough sample. Part of the analysis has to be an eyeball test -- is this \"significant\" because they are truly different, or because I have many subjects.\n:::\n\n# Independent Samples t-test\n\n[Chapter 13.3 in Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#studentttest)\n\nTwo different types: Student's & Welch's\n\n-   Start with Student's t-test which assumes equal variances between the groups\n\n$$\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{SE(\\bar{X_1} - \\bar{X_2})}\n$$\n\n------------------------------------------------------------------------\n\n## Student's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/student_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Student's t-test: Calculate SE\n\nAre able to use a pooled variance estimate\n\nBoth variances/standard deviations are assumed to be equal\n\nTherefore:\n\n$$\nSE(\\bar{X_1} - \\bar{X_2}) = \\hat{\\sigma} \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}\n$$\n\nWe are calculating the **Standard Error of the Difference between means**\n\nDegrees of Freedom: Total N - 2\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R\n\nUsing the `independentSamplesTest()` within the `lsr` library (make sure it is installed) we can run the test *very* easily\n\nFormula is outcome \\~ group\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE #default is FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Student's independent samples t-test \n\nOutcome variable:   Sleep_Hours_Schoolnight \nGrouping variable:  Region \n\nDescriptive statistics: \n               NM    NY\n   mean     6.989 6.994\n   std dev. 1.379 1.512\n\nHypotheses: \n   null:        population means equal for both groups\n   alternative: different population means in each group\n\nTest results: \n   t-statistic:  -0.024 \n   degrees of freedom:  180 \n   p-value:  0.981 \n\nOther information: \n   two-sided 95% confidence interval:  [-0.428, 0.418] \n   estimated effect size (Cohen's d):  0.004 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function. It doesn't look as nice, but you will likely encounter it when searching for help\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  Sleep_Hours_Schoolnight by Region\nt = -0.023951, df = 180, p-value = 0.9809\nalternative hypothesis: true difference in means between group NM and group NY is not equal to 0\n95 percent confidence interval:\n -0.4281648  0.4178954\nsample estimates:\nmean in group NM mean in group NY \n        6.989247         6.994382 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Student's t-test: Write-up\n\nThe mean amount of sleep in New Mexico for youth was 6.989 (SD = 1.379), while the mean in New York was 6.994 (SD = 1.512). A Student's independent samples t-test showed that there was not a significant mean difference (*t*(180)=-0.024, *p*=.981, $CI_{95}$=\\[-0.43, 0.42\\], *d*=.004). This suggests that there is no difference between youth in NM and NY on amount of sleep on school nights.\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#https://indrajeetpatil.github.io/ggstatsplot/\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n::: {.cell-output-display}\n![](07_ComparingMeans_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Welch's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/welch_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: Calculate SE\n\nSince the variances are not equal, we have to estimate the SE differently\n\n$$ SE(\\bar{X_1} - \\bar{X_2}) = \\sqrt{\\frac{\\hat{\\sigma_1^2}}{N_1} + \\frac{\\hat{\\sigma_2^2}}{N_2}} $$\n\nDegrees of Freedom is also very different:\n\n![](/images/welch_df.png){fig-align=\"center\" width=\"380\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R\n\nWe use the same function as before, but specify that the variances are not equal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Welch's independent samples t-test \n\nOutcome variable:   Sleep_Hours_Schoolnight \nGrouping variable:  Region \n\nDescriptive statistics: \n               NM    NY\n   mean     6.989 6.994\n   std dev. 1.379 1.512\n\nHypotheses: \n   null:        population means equal for both groups\n   alternative: different population means in each group\n\nTest results: \n   t-statistic:  -0.024 \n   degrees of freedom:  176.737 \n   p-value:  0.981 \n\nOther information: \n   two-sided 95% confidence interval:  [-0.429, 0.419] \n   estimated effect size (Cohen's d):  0.004 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function...turns out it is pretty straightforward\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  Sleep_Hours_Schoolnight by Region\nt = -0.023902, df = 176.74, p-value = 0.981\nalternative hypothesis: true difference in means between group NM and group NY is not equal to 0\n95 percent confidence interval:\n -0.4290776  0.4188082\nsample estimates:\nmean in group NM mean in group NY \n        6.989247         6.994382 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Cool Visualizations\n\nThe library [ggstatsplot](https://indrajeetpatil.github.io/ggstatsplot/) has some wonderful visualizations of various tests\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n::: {.cell-output-display}\n![](07_ComparingMeans_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n# In-Class Lab\n\nTake a look at the data in `state_school` and identify another Independent Samples t-test that you can perform\n\n::: nonincremental\n-   Be sure to select (1) a grouping variable and (2) a continuous variable to look at differences between the groups\n:::\n\nFollow the steps that we went through today:\n\n::: nonincremental\n1.  Check for Normality of the variable\n2.  Check for Homogeneity of Variances\n3.  Perform the appropriate t-test\n4.  Report Results\n:::\n\n**Knit the document**\n\n------------------------------------------------------------------------\n\n## Next Time...\n\nPaired Samples t-test\n\n# Paired Samples t-Test in R\n\n[Chapter 13.5 - Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#pairedsamplesttest)\n\nAlso called \"Dependent Samples t-test\"\n\n-   We have been testing means between two *independent* samples. Participants may be randomly assigned to the separate groups\n\n    -   This is limited to those types of study designs, but what if we have repeated measures?\n\n-   We will then need to compare scores across people...the samples we are comparing now *depend* on one another and are *paired*\n\n------------------------------------------------------------------------\n\n# Common Mistakes and Pitfalls\n\n-   **Misinterpreting p-Values**\n\n-   **Violations of Assumptions**\n\n-   **Sample Size Considerations**\n\n-   **Multiple Testing Issues**\n\n------------------------------------------------------------------------\n\n## Next time...\n",
    "supporting": [
      "07_ComparingMeans_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}