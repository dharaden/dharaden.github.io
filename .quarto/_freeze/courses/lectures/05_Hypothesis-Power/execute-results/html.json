{
  "hash": "bd42ea4dfa13f76175070ffaa7bcdfc0",
  "result": {
    "markdown": "---\ntitle: \"Wk 5 - Hypothesis & Power\"\nsubtitle: \"PSYC 640 - Fall 2023\"\nauthor: \"Dustin Haraden\"\nformat: \n  revealjs:\n    multiplex: true\n    slide-number: true\n    incremental: true\n    touch: true\n    code-overflow: wrap\n    theme: night\nexecute: \n  echo: true\neditor: visual\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Recap\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(pwr)\nlibrary(ggpubr)\nlibrary(transformr)\n```\n:::\n\n\n-   Sample statistics are biased estimates of the population\n\n-   Can construct confidence intervals around our sample statistics\n\n    -   We use (so far) the normal distribution & the t-distribution\n\n-   **Up Next...Hypothesis testing!**\n\n## Hypothesis\n\nWhat is a hypothesis?\n\nIn statistics, a **hypothesis** is a statement about the population. It is usually a prediction that a parameter describing some characteristic of a variable takes a particular numerical value, or falls into a certain range of values.\n\n------------------------------------------------------------------------\n\n## Hypothesis\n\nFor example, dogs are characterized by their ability to read humans' social cues, but it is (was) unknown whether that skill is biologically prepared. I might hypothesize that when a human points to a hidden treat, puppies do not understand that social cue and their performance on a related task is at-chance. We would call this a **research hypothesis.**\n\nThis could be represented numerically as, as a **statistical hypothesis**:\n\n$$\\text{Proportion}_{\\text{Correct Performance}} = .50$$\n\n------------------------------------------------------------------------\n\n## The null hypothesis\n\nIn Null Hypothesis Significance Testing, we... test a null hypothesis.\n\nA **null hypothesis** ( $H_0$ ) is a statement of no effect. The *research hypothesis* states that there is no relationship between X and Y, or our intervention has no effect on the outcome.\n\n-   The *statistical hypothesis* is either that the population parameter is a single value, like 0, or that a range, like 0 or smaller.\n\n------------------------------------------------------------------------\n\n## The alternative hypothesis\n\nAccording to probability theory, our sample space must cover all possible elementary events. Therefore, we create an **alternative hypothesis** ( $H_1$ ) that is every possible event not represented by our null hypothesis.\n\n::: columns\n::: {.column width=\"50%\"}\n$$H_0: \\mu = 4$$ $$H_1: \\mu \\neq 4$$\n:::\n\n::: {.column width=\"50%\"}\n$$H_0: \\mu \\leq -7$$ $$H_1: \\mu > -7$$\n:::\n:::\n\n------------------------------------------------------------------------\n\n## The tortured logic of NHST\n\nWe create two hypotheses, $H_0$ and $H_1$. Usually, we care about $H_1$, not $H_0$. In fact, what we really want to know is how likely $H_1$, given our data.\n\n$$P(H_1|Data)$$ Instead, we're going to test our null hypothesis. Well, not really. We're going to assume our null hypothesis is true, and test how likely we would be to get these data.\n\n$$P(Data|H_0)$$\n\n------------------------------------------------------------------------\n\n## Example #1\n\nConsider the example of puppies' abilities to read human social cues.\n\nLet $\\Pi$ be the probability the puppy chooses the correct cup that a person points to.\n\nIn a task with two choices, an at-chance performance is $\\Pi = .5$. This can be the null hypothesis because if this is true, than puppies would make the correct choice as often as they would make an incorrect choice.\n\nNote that the null hypothesis changes depending on the situation and research question.\n\n------------------------------------------------------------------------\n\n## Example #1 - Hypotheses\n\nAs a dog-lover, you're skeptical that reading human social cues is purely learned, and you have an alternative hypothesis that puppies will perform well over chance, thus having a probability of success on any given task greater than .5.\n\n$$H_0: \\Pi = .5$$ $$H_1: \\Pi \\neq .5$$\n\n## Example #1\n\nTo test the null hypothesis, you a single puppy and test them 12 times on a pointing task. The puppy makes the correct choice 10 times.\n\nThe question you're going to ask is:\n\n::: nonincremental\n-   \"How likely is it that the puppy is successful 10 times out of 12, if the probability of success is .5?\"\n:::\n\nThis is the essence of NHST.\n\nYou can already test this using what you know about the binomial distribution.\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntrial = 0:12\ndata.frame(trial = trial, d = dbinom(trial, size = 12, prob = .5), \n           color = ifelse(trial == 10, \"1\", \"2\")) %>%\n  ggplot(aes(x = trial, y = d, fill = color)) +\n  geom_bar(stat = \"identity\") + \n  guides(fill = \"none\")+\n  scale_x_continuous(\"Number of puppy successes\", breaks = c(0:12))+\n  scale_y_continuous(\"Probability of X successes\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(10, size = 12, prob = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01611328\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Complications with the binomial\n\nThe likelihood of the puppy being successful 10 times out of 12 *if the true probability of success is .5* is 0.02. That's pretty low! That's so low that we might begin to suspect that the true probability is not .5.\n\nBut there's a problem with this example. [The real study](https://doi.org/10.1016/j.anbehav.2020.05.019) used a sample of many puppies (\\>300), and the average number of correct trials per puppy was about 8.33. But the binomial won't allow us to calculate the probability of fractional successes!\n\nWhat we really want is not to assess 10 out of 12 times, but a proportion, like .694. How many different proportions could result puppy to puppy?\n\n------------------------------------------------------------------------\n\n## Our statistic is usually continuous\n\nWhen we estimate a statistic for our sample -- like the proportion of puppy success, or the average IQ score, or the relationship between age in months and second attending to a new object -- that statistic is nearly always continuous. So we have to assess the probability of that statistic using a probability distribution for continuous variables, like the normal distribution. (Or *t*, or *F*, or $\\chi^2$ ).\n\nWhat is the probability of any value in a continuous distribution?\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[Instead of calculating the probability of our statistic, we calculate the probability of our statistic *or more extreme* under the null.<br><br>The probability of success on 10 trials out of 12 or more extreme is 0.01.]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(trials = trial, d = dbinom(trial, size = 12, prob = .5), \n           color = ifelse(trial %in% c(0,1,2, 10,11,12), \"1\", \"2\")) %>%\n  ggplot(aes(x = trials, y = d, fill = color)) +\n  geom_bar(stat = \"identity\") + \n  guides(fill = \"none\")+\n  scale_x_continuous(\"Number of successes\", breaks = c(0:12))+\n  scale_y_continuous(\"Probability of X successes\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/sampling_binom-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[As we have more trials...]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(trials = 0:24, \n           d = dbinom(0:24, size = 24, prob = .5), \n           color = ifelse(0:24 %in% c(0:4, 20:24), \"1\", \"2\")) %>%\n  ggplot(aes(x = trials, y = d, fill = color)) +\n  geom_bar(stat = \"identity\") + \n  guides(fill = \"none\")+\n  scale_x_continuous(\"Number of trials hired\", breaks = c(0:24))+\n  scale_y_continuous(\"Probability of X trials hired\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[... and more trials...]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(trials = 0:36, \n           d = dbinom(0:36, size = 36, prob = .5), \n           color = ifelse(0:36 %in% c(0:6, 30:36), \"1\", \"2\")) %>%\n  ggplot(aes(x = trials, y = d, fill = color)) +\n  geom_bar(stat = \"identity\") + \n  guides(fill = \"none\")+\n  scale_x_continuous(\"Number of trials hired\", breaks = c(0:36))+\n  scale_y_continuous(\"Probability of X trials hired\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[If our measure was continuous, it would look something like this.]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ngg_color_hue <- function(n) {\n  hues = seq(15, 375, length = n + 1)\n  hcl(h = hues, l = 65, c = 100)[1:n]\n}\n\ncolors = gg_color_hue(2)\n\ndata.frame(x = seq(-4,4)) %>%\n  ggplot(aes(x=x)) +\n  stat_function(fun = function(x) dnorm(x), geom = \"area\", fill = colors[2])+\n  stat_function(fun = function(x) dnorm(x), xlim = c(-4, -2.32), geom = \"area\", fill = colors[1])+\n  stat_function(fun = function(x) dnorm(x), xlim = c(2.32, 4), geom = \"area\", fill = colors[1])+\n  geom_hline(aes(yintercept = 0)) +\n  scale_x_continuous(breaks = NULL)+\n  labs(x = \"successes\",\n       y = \"Probability of X successes\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n## Quick recap\n\nFor any NHST test, we:\n\n1.  Identify the null hypothesis ( $H_0$ ), which is usually the opposite of what we think to be true.\n\n2.  Collect data.\n\n3.  Determine how likely we are to get these data or more extreme if the null is true.\n\n------------------------------------------------------------------------\n\nWhat's missing?\n\n4.  How do we determine what the distribution looks like if the null hypothesis is true?\n\n5.  How unlikely do the data have to be to \"reject\" the null?\n\n------------------------------------------------------------------------\n\n## Enter sampling distributions\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(trials = trial, d = dbinom(trial, size = 12, prob = .5), \n           color = ifelse(trial %in% c(0,1,2, 10,11,12), \"1\", \"2\")) %>%\n  ggplot(aes(x = trials, y = d, fill = color)) +\n  geom_bar(stat = \"identity\") + \n  guides(fill = \"none\")+\n  scale_x_continuous(\"Number of successes\", breaks = c(0:12))+\n  scale_y_continuous(\"Probability of X successes\") +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nWhen we were analyzing the puppy problem, we built the distribution under the null using the binomial.\n\nThis is our **sampling distribution.**\n:::\n:::\n\n------------------------------------------------------------------------\n\nBut as we said before, we're not really going to use the binomial much to make inferences about statistics, because the vast majority of our statistics are ***continuous***, not discrete. Instead, we'll use other distributions to create our sampling distributions. Sometimes $t$ , or $F$ , or $\\chi^2$ .\n\n------------------------------------------------------------------------\n\n## Example #2\n\nBray and colleagues (2020) test a sample of 10\\* puppies on multiple cognitive tasks, including their ability to correctly find a treat hidden under one of two cups based on human pointing. The average success rate was 69.41% (SD = 18.88).\n\nHow do you generate the sampling distribution around the null?\n\n::: notes\nNull: distribution of successes -- you know this population, trying to see if ratings of female applicants come from the same distribution of scores\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[The mean of the sampling distribution = the mean of the null hypothesis<br><br>The standard deviation of the sampling distribution:]{style=\"font-size:30px;\"}\n\n$$\\small SEM = \n\\frac{\\sigma}{\\sqrt{N}}$$\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(0,100)) %>%\n  ggplot(aes(x=x)) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(10)), \n                geom = \"area\", fill = \"purple\", alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(5)), \n                geom = \"area\", fill = \"red\", alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(2)), \n                geom = \"area\", fill = \"blue\", alpha = .5) +\n      labs(title = as.expression(bquote(\"Population\"~mu~\"=50\"~sigma~\"=5.97\")),\n           x = \"Average proportion of successes\",\n           y = NULL)  +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n::: notes\nWhat must we assume in order to use the SEM?\n\nRandom sampling\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"30%\"}\n[The mean of the sampling distribution = the mean of the null hypothesis<br><br>The standard deviation of the sampling distribution:]{style=\"font-size:30px;\"}\n\n$$\\small SEM = \\frac{\\sigma}{\\sqrt{N}}$$\n:::\n\n::: {.column width=\"70%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsem = 18.88/sqrt(10)\ndata.frame(x = seq(0,100)) %>%\n  ggplot(aes(x=x)) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = sem), \n                geom = \"area\", alpha = .75) +\n      labs(title = as.expression(bquote(\"Population\"~mu~\"=50\"~sigma~\"=5.97\")),\n           x = \"Average proportion of successes\",\n           y = NULL)  +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n::: notes\nCalculate SEM on board.\n\n$sqrt(10) = 3.1622777$\n:::\n\n------------------------------------------------------------------------\n\nNote that we didn't have access to the population standard deviation -- we had to make use of the sample standard deviation instead:\n\n$$SEM = \\frac{\\hat{\\sigma}}{\\sqrt{N}} = \\frac{s}{\\sqrt{N}}$$\n\nSo long as your estimate of the standard deviation is already corrected for bias (you've divided by $N-1$ ), then you can swap in your sample SD.\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(0,100)) %>%\n  ggplot(aes(x=x)) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(10)), \n                geom = \"area\") +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(10)), \n                geom = \"area\", xlim = c(0, 35.81), fill = colors[1]) +\n  stat_function(fun = function(x) dnorm(x, mean = 50, sd = 18.88/sqrt(10)), \n                geom = \"area\", xlim = c(64.19, 100), fill = colors[1]) +\n  geom_vline(aes(xintercept = 64.19), color = \"purple\") +\n      labs(title = as.expression(bquote(\"Population\"~mu~\"=50\"~sigma~\"=5.97\")),\n           x = \"Average proportion of successes\",\n           y = NULL)  +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/sampling-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nM <-  50\ns <-  18.88\nN <-  10\nX <-  69.41\n\nsem = s/sqrt(N)\n\nz <-  (X-M)/sem\n```\n:::\n\n\n[We have a normal distribution for which we know the mean (M), the standard deviation (SEM), and a score of interest ( $\\bar{X}$ ).<br>]{style=\"font-size:30px;\"}\n:::\n:::\n\nWe can use this information to calculate a z-score; in the context of comparing one mean to a sampling distribution of means, we call this a ***z-statistic***.\n\n$$Z = \\frac{\\bar{X}- M}{SEM} = \\frac{69.41-50}{5.97} = 3.25$$\n\n------------------------------------------------------------------------\n\n$$Z = \\frac{\\bar{X}- M}{SEM} = \\frac{69.41-50}{5.97} = 3.25$$\n\nAnd here's where we use the properties of the Standard Normal Distribution to calculate probabilities, specifically the probability of getting a score this far away from $\\mu$ or more extreme:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(-3.25) + pnorm(3.25, lower.tail = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.00115405\n```\n:::\n\n```{.r .cell-code}\npnorm(-3.25)*2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.00115405\n```\n:::\n:::\n\n\nThe probability that the average puppy's success rate would be at least 19.41 percentage points away from at-chance (50/%) 0.001.\n\n------------------------------------------------------------------------\n\nThe probability that the average puppy's success rate would be at least 19.41 percentage points away from at-chance (50/%) 0.001.\n\n-   0.001 is our p-value.\n\n-   What does this mean?\n\n------------------------------------------------------------------------\n\n## A p-value DOES NOT:\n\n-   Tell you that the probability that the null hypothesis is true.\n\n-   Prove that the alternative hypothesis is true.\n\n-   Tell you anything about the size or magnitude of any observed difference in your data.\n\n------------------------------------------------------------------------\n\n### p-values and error\n\nConsider what the p-value means. In a world where the null ( $H_0$ ) is true, then by chance, we'll get statistics in the extreme. Specifically, we'll get them $\\alpha$ proportion of the time. So $\\alpha$ is our tolerance for False Positives or incorrectly rejecting the null.\n\n------------------------------------------------------------------------\n\n## $p$-values\n\nFisher established (rather arbitrarily) the sanctity of the .05 and .01 significance levels during his work in agriculture, including work on the effectiveness of fertilizer. A common source of fertilizer is cow manure. Male cattle are called bulls.\n\nA common misinterpretation of the $p$-value ( $\\alpha$ ) is that it is the probability of the null hypothesis being wrong.\n\nAnother common misunderstanding is that $1-\\alpha$ is the probability that results will replicate.\n\n------------------------------------------------------------------------\n\n## $p$-values\n\n-   In most research, the probability that the null hypothesis is true is very small.\n\n-   If the null hypothesis is false, then the only mistake to be made is a **failure to detect a real effect**.\n\n------------------------------------------------------------------------\n\nWe collect a sample and compare this to a null hypothesis: $H_0: \\mu_0 = 100$. Holding our sample mean $(\\bar{X} = 105)$ constant, how does our $p$-value change as our sample size gets larger?\n\n\n::: {.cell hash='05_Hypothesis-Power_cache/revealjs/unnamed-chunk-12_d7c05570202b1a68c22d25b899bf0043'}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(\n  m = 100, \n  s = 15, \n  n = seq(5, 150, 5)) %>%\n  mutate(\n    X = map(n, ~c(85:115)),\n    density = map(n, ~dnorm(x = 85:115, m = 100, s = 15/sqrt(.x))),\n    pvalue = map(n, ~pnorm(5/(15/sqrt(.x)), lower.tail = F)*2),\n    pvalue = map_chr(pvalue, papaja::printp)) %>%\n  unnest(cols = c(X, density)) %>%\nggplot(aes(x=X, y=density, frame=n)) + \n  geom_line() + \n  geom_vline(aes(xintercept = 105), color = \"purple\") +\n  geom_label(aes(x = 107, y = .2, label = paste(\"p:\", pvalue)), hjust = 0) +\n  labs(x = \"X\",\n       y = \"density\",\n       title = \"N = {closest_state}\") +\n  transition_states(n,\n                    transition_length = 10,\n                    state_length = 2) +\n  theme_pubr()\n```\n\nNULL\n:::\n\n\n------------------------------------------------------------------------\n\nIf the null hypothesis is false, then the significance test is akin to a test of whether the sample size was large enough.\n\nBecause Null Hypothesis Significance Testing (NHST) is beginning to seem like a bit of a sham, some have suggested we start calling it Statistical Hypothesis Inference Testing.\n\n------------------------------------------------------------------------\n\n## Errors\n\nIn hypothesis testing, we can make two kinds of errors.\n\n|             |   Reject $H_0$   |  Do not reject   |\n|------------:|:----------------:|:----------------:|\n|  $H_0$ True |   Type I Error   | Correct decision |\n| $H_0$ False | Correct decision |  Type II Error   |\n\nFalsely rejecting the null hypothesis is a **Type I error**. Traditionally, this has been viewed as particularly important to control at a low level (akin to avoiding false conviction of an innocent defendant).\n\n------------------------------------------------------------------------\n\n## Errors\n\nIn hypothesis testing, we can make two kinds of errors.\n\n|             |   Reject $H_0$   |  Do not reject   |\n|------------:|:----------------:|:----------------:|\n|  $H_0$ True |   Type I Error   | Correct decision |\n| $H_0$ False | Correct decision |  Type II Error   |\n\nFailing to reject the null hypothesis when it is false is a **Type II error**. This is sometimes viewed as a failure in signal detection.\n\n------------------------------------------------------------------------\n\n## Errors\n\nIn hypothesis testing, we can make two kinds of errors.\n\n|             |   Reject $H_0$   |  Do not reject   |\n|------------:|:----------------:|:----------------:|\n|  $H_0$ True |   Type I Error   | Correct decision |\n| $H_0$ False | Correct decision |  Type II Error   |\n\nNull hypothesis testing is designed to make it easy to control Type I errors. We set a minimum proportion of such errors that we would be willing to tolerate in the long run. This is the significance level ( $\\alpha$ ). By tradition this is no greater than .05.\n\n------------------------------------------------------------------------\n\n## Errors\n\nIn hypothesis testing, we can make two kinds of errors.\n\n|             |   Reject $H_0$   |  Do not reject   |\n|------------:|:----------------:|:----------------:|\n|  $H_0$ True |   Type I Error   | Correct decision |\n| $H_0$ False | Correct decision |  Type II Error   |\n\nControlling Type II errors is more challenging because it depends on several factors. But, we usually DO want to control these errors. Some argue that the null hypothesis is usually false, so the only error we can make is a Type II error -- a failure to detect a signal that is present. **Power** is the probability of correctly rejecting a false null hypothesis.\n\n------------------------------------------------------------------------\n\n### Some Greek letters\n\n$\\alpha$ : The rate at which we make Type I errors, which is the same $\\alpha$ as the cut-off for $p$ -values.\n\n$\\beta$ : The rate at which we make Type II errors.\n\n$1-\\beta$ : statistical power.\n\nNote that all these probability statements are being made in the frequentist sense -- in the long run, we expect to make Type I errors $\\alpha$ proportion of the time and Type II errors $\\beta$ proportion of the time.\n\n------------------------------------------------------------------------\n\nControlling Type II errors is the goal of power analysis and must contend with four quantities that are interrelated:\n\n::: columns\n::: {.column width=\"50%\"}\n-   Sample size\n-   Effect size\n:::\n\n::: {.column width=\"50%\"}\n-   Significance level ( $\\alpha$ )\n-   Power\n:::\n:::\n\n-   When any three are known, the remaining one can be determined. Usually this translates into determining the power present in a research design (**post-hoc power analysis** ), or, determining the sample size necessary to achieve a desired level of power. We will need to define the null-hypothesis value\n\n------------------------------------------------------------------------\n\nSuppose we have a measure of social sensitivity that we have administered to a ***random sample of 25*** psychology students. This measure has a population mean ( $\\mu$ ) of 100 and a standard deviation ( $\\sigma$ ) of 20. We suspect that psychology students are more sensitive to others than is typical and want to know if their mean, which is 110, is sufficient evidence to reject the null hypothesis that they are no more sensitive than the rest of the population.\n\n-   We would also like to know how likely it is that we could make a mistake by concluding that psychology students are not different when they really are: A Type II error.\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"40%\"}\n[We begin by defining the location in the null hypothesis distribution beyond which empirical results would be considered sufficiently unusual to lead us to reject the null hypothesis. We control these mistakes (Type I errors) at the chosen level of significance ( $\\alpha = .05$ ).]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmu = 100\nxbar = 110\ns = 20\nn = 25\nsem = s/sqrt(n)\ncv = qnorm(mean = mu, sd = sem, p = .025, lower.tail = F)\ncv2 = qnorm(mean = mu, sd = sem, p = .025, lower.tail = T)\n\nggplot(data.frame(x = seq(70, 130)), aes(x)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv, 130), fill = \"red\") +\n  geom_vline(aes(xintercept = cv), color = \"red\")+\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv2, 70), fill = \"red\") +\n  geom_vline(aes(xintercept = mu))+\n  geom_hline(aes(yintercept = 0))+\n  scale_x_continuous(\"Means\", breaks = seq(70,130,10)) +\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/student null-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n::: notes\nHow do we figure out where this region is?\n\nStart with our $\\alpha$ level (.05)\n\nGiven our distribution parameters, what Z-value corresponds to .05 above that line\n\nmu = 100 x = 110 s = 20 n = 25 sem = 4 z = 1.96\n:::\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"40%\"}\n$$\\small \\text{Critical Value} \\\\= \\mu_0 + Z_{.975}\\frac{\\sigma}{\\sqrt{N}}\\\\= 100 + 1.96\\frac{20}{\\sqrt{25}} \\\\= 107.84$$\n\n[What if the null hypothesis is false? How likely are we to correctly reject the null hypothesis in the long run?]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmu = 100\nxbar = 110\ns = 20\nn = 25\nsem = s/sqrt(n)\ncv = qnorm(mean = mu, sd = sem, p = .025, lower.tail = F)\ncv2 = qnorm(mean = mu, sd = sem, p = .025, lower.tail = T)\n\nggplot(data.frame(x = seq(70, 130)), aes(x)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv, 130), fill = \"red\") +\n  geom_vline(aes(xintercept = cv), color = \"red\")+\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv2, 70), fill = \"red\") +\n  geom_vline(aes(xintercept = mu))+\n  geom_hline(aes(yintercept = 0))+\n  scale_x_continuous(\"Means\", breaks = seq(70,130,10)) +\n  scale_y_continuous(NULL, breaks = NULL)+\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(70, 140)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = function(x) dnorm(x, mean = mu, sd = sem), \n                 geom = \"line\") +\n  stat_function(aes(fill = \"Type I error\"), fun = function(x) dnorm(x, mean = mu, sd = sem), \n                 geom = \"area\", xlim = c(cv, 140),\n                alpha = .5) +\n  stat_function(aes(fill = \"Type I error\"), fun = function(x) dnorm(x, mean = mu, sd = sem), \n                 geom = \"area\", xlim = c(70, cv2),\n                alpha = .5) +\n  geom_vline(aes(xintercept = cv, color = \"Critical Value\")) +\n  guides(color = \"none\") +\n  scale_x_continuous(limits = c(70,140), breaks = seq(70, 140, 10)) +\n  scale_y_continuous(breaks = NULL) +\n  labs(x = \"Mean\", y = \"density\", fill = NULL)+\n  theme_pubr()\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(70, 140)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = function(x) dnorm(x, mean = mu, sd = sem),\n                 geom = \"line\", alpha = .2) +\n  geom_vline(aes(xintercept = cv, color = \"Critical Value\")) +\n  guides(color = \"none\") +\n  scale_x_continuous(limits = c(70,140), breaks = seq(70, 140, 10)) +\n  scale_y_continuous(breaks = NULL) +\n  labs(x = \"Mean\", y = \"density\", fill = NULL)+\n  theme_pubr()\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(70, 140)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = function(x) dnorm(x, mean = mu, sd = sem),\n                 geom = \"line\", alpha = .2) +\n  stat_function(fun = function(x) dnorm(x, mean = xbar, sd = sem),\n                 geom = \"line\") +\n  geom_vline(aes(xintercept = cv, color = \"Critical Value\")) +\n  guides(color = \"none\") +\n  scale_x_continuous(limits = c(70,140), breaks = seq(70, 140, 10)) +\n  scale_y_continuous(breaks = NULL) +\n  labs(x = \"Mean\", y = \"density\", fill = NULL)+\n  theme_pubr()\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(x = seq(70, 140)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = function(x) dnorm(x, mean = mu, sd = sem),\n                 geom = \"line\", alpha = .2) +\n  stat_function(fun = function(x) dnorm(x, mean = xbar, sd = sem),\n                 geom = \"line\") +\n  stat_function(aes(fill = \"Power\"), fun = function(x) dnorm(x, mean = xbar, sd = sem),\n                 geom = \"area\", xlim = c(cv, 140),\n                alpha = .5) +\n  stat_function(aes(fill = \"Type II error\"), fun = function(x) dnorm(x, mean = xbar, sd = sem),\n                 geom = \"area\", xlim = c(70, cv),\n                alpha = .5) +\n  geom_vline(aes(xintercept = cv, color = \"Critical Value\")) +\n  guides(color = \"none\") +\n  scale_x_continuous(limits = c(70,140), breaks = seq(70, 140, 10)) +\n  scale_y_continuous(breaks = NULL) +\n  labs(x = \"Mean\", y = \"density\", fill = NULL)+\n  theme_pubr()\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n\n[To determine the probability of a Type II error, we must specify a value for the alternative hypothesis. We will use the sample mean of 110.<br><br>In the long run, if psychology samples have a mean of 110 ( $\\sigma = 20$, $N = 25$ ), we will correctly reject the null with probability of 0.71 (power). We will incorrectly fail to reject the null with probability of 0.29 ( $\\beta$ ).]{style=\"font-size:30px;\"}\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/student null and alt-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## Example Errors\n\n|             |         Reject $H_0$         |        Do not reject         |\n|------------:|:----------------------------:|:----------------------------:|\n|  $H_0$ True | Type I Error $\\alpha$ = 0.05 |       Correct decision       |\n| $H_0$ False |       Correct decision       | Type II Error $\\beta$ = 0.29 |\n\n: In the long run, if psychology samples have a mean of 110 ($\\sigma$ = 20, $N$ = 25), we will correctly reject the null with probability of 0.71 (power; 1 - $\\beta$). We will incorrectly fail to reject the null with probability of 0.29 ( $\\beta$ )\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n[**Another way to determine these values:** Once the critical value and alternative value is established, we can determine the location of the critical value in the alternative distribution.]{style=\"font-size:30px;\"}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.540036\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n$$Z_1 = \\frac{CV_0 - \\mu_1}{\\frac{\\sigma}{\\sqrt{N}}}$$ $$Z_1 = \\frac{107.84 - 110}{\\frac{20}{\\sqrt{25}}} = -0.54$$\n\n[The proportion of the alternative distribution that falls below that point is the probability of a Type II error (.29); power is then .71.]{style=\"font-size:30px;\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(-.54)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2945985\n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n## What if these factors change?\n\n::: columns\n::: {.column width=\"50%\"}\nSample size ( $N$ )\n\nEffect size ( Right now it is difference between means )\n:::\n\n::: {.column width=\"50%\"}\nSignificance level ( $\\alpha$ )\n\nPower ( $\\beta$ )\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Changing Effect Size\n\nThe choice of 110 as the mean of $H_1$ is completely arbitrary. What if we believe that the alternative mean is 115? This larger signal should be easier to detect.\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n\n$$Z_1 = \\frac{107.84 - 115}{\\frac{20}{\\sqrt{25}}} = -1.79$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pnorm(-1.79) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.963273\n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Increase Sample Size\n\nWhat if instead we increase the **sample size**? This will reduce variability in the sampling distribution, making the difference between the null and alternative distributions easier to see. (New $N$ is 50.)\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n\n$\\text{CV} = 100 + 1.96\\frac{20}{\\sqrt{50}} = 105.54$ $$Z_1 = \\frac{105.54 - 110}{\\frac{20}{\\sqrt{50}}} = -1.58$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pnorm(-1.57) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9417924\n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Update $\\alpha$\n\nWhat if we decrease the significance level to .01?\\\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nThat will move the critical value:\n\n\n::: {.cell}\n\n:::\n\n\n$\\text{CV} = 100 + 2.58\\frac{20}{\\sqrt{25}} = 110.3$ $$Z_1 = \\frac{110.3 - 110}{\\frac{20}{\\sqrt{25}}} = 0.08$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pnorm(.08) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4681186\n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\nOops, we've been ignoring the other tail. So far it hasn't mattered (the area has been so small) but it makes a difference when $H_0$ and $H_1$ overlap significantly.\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n$$Z_1 = \\frac{107.84 - 102}{\\frac{20}{\\sqrt{25}}} = 1.46$$ $$Z_2 = \\frac{92.16 - 102}{\\frac{20}{\\sqrt{25}}} = -2.46$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1-pnorm(1.46) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.07214504\n```\n:::\n\n```{.r .cell-code}\npnorm(-2.46)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.006946851\n```\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\nMore generally we can determine the relationship between effect size and power for a constant $\\alpha$ (.05) and sample size ( $N = 20$ ).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npwr_fun = function(m1, m2, alpha, n, sd){\n  sem = sd/sqrt(n)\n  cv = qnorm(p = 1-(alpha/2), mean = m1, sd = sem)\n  z_1 = (cv-m2)/sem\n  power = pnorm(q = z_1, lower.tail = F)\n  return(power)\n}\n\nsize = seq(100, 120, 1)\n\ndata.frame(effect = size, power = sapply(size, function(x) pwr_fun(m1 = 100, m2 = x, alpha = .05, n = 20, sd = 20))) %>%\n  ggplot(aes(x = effect, y = power)) +\n  geom_line(size = 1.5) +\n  scale_x_continuous(expression(H[1]~Mean)) +\n  ggtitle(\"Power to detect significant effect by mean\") +\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-38-1.png){width=1440}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nLikewise, we can display the relationship between sample size and power for a constant $\\alpha$ and effect size.\n\nBelow is difference of means 100 to 110 in our example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsize = seq(5,200,5)\n\ndata.frame(size = size, power = sapply(size, function(x) pwr_fun(m1 = 100, m2 = 110, alpha = .05, n = x, sd = 20))) %>%\n  ggplot(aes(x = size, y = power)) +\n  geom_line(size = 1.5) +\n  scale_x_continuous(\"Sample Size\") +\n  ggtitle(\"Power to detect significant effect by sample size\") +\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-39-1.png){width=1440}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nPower changes as a function of significance level for a constant effect size and sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsize = seq(.01,.20,.01)\n\ndata.frame(alpha = size, \n           power = sapply(size, function(x) pwr_fun(m1 = 100, \n                                                    m2 = 110, \n                                                    alpha = x, \n                                                    n = 20, \n                                                    sd = 20))) %>%\n  ggplot(aes(x = alpha, y = power)) +\n  geom_line(size = 1.5) +\n  scale_x_continuous(expression(alpha)) +\n  ggtitle(\"Power to detect significant effect by alpha\") +\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-40-1.png){width=1440}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nFor a one-tailed test, we put the entire rejection area into a single tail. If $\\alpha = .05$, then one tail contains .05 and critical values will be either 1.64 or -1.64 standard errors away from the null mean.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmu = 100\nx = 110\ns = 20\nn = 25\nsem = s/sqrt(n)\ncv_sngle = qnorm(mean = mu, sd = sem, p = .05, lower.tail = F)\n\nggplot(data.frame(x = seq(70, 130)), aes(x)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv_sngle, 130), fill = \"red\") +\n  geom_vline(aes(xintercept = cv_sngle), color = \"red\")+\n  geom_vline(aes(xintercept = mu))+\n  geom_hline(aes(yintercept = 0))+\n  scale_x_continuous(\"Means\", breaks = seq(70,130,10)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-41-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nA two-tailed test is less powerful (more conservative) than a one-tailed test for the same sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npwr1_fun = function(m1, m2, alpha, n, sd){\n  sem = sd/sqrt(n)\n  cv = qnorm(p = 1-(alpha), mean = m1, sd = sem)\n  z_1 = (cv-m2)/sem\n  power = pnorm(q = z_1, lower.tail = F)\n  return(power)\n}\npwr2_fun = function(m1, m2, alpha, n, sd){\n  sem = sd/sqrt(n)\n  cv_1 = qnorm(p = 1-(alpha/2), mean = m1, sd = sem)\n  cv_2 = qnorm(p = (alpha/2), mean = m1, sd = sem)\n  z_1 = (cv_1-m2)/sem\n  z_2 = (cv_2-m2)/sem\n  power = pnorm(q = z_1, lower.tail = F) + pnorm(q = z_2, lower.tail = T)\n  return(power)\n}\n\nsize = seq(5,100,5)\n\ndata.frame(effect = size, \n           power_1 = sapply(size, function(x) pwr1_fun(m1 = 100, m2 = 110, alpha = .05, n = x, sd = 20)),\n           power_2 = sapply(size, function(x) pwr2_fun(m1 = 100, m2 = 110, alpha = .05, n = x, sd = 20))) %>%\n  ggplot(aes(x = effect)) +\n  geom_line(aes(y = power_1, color = \"one-tail\"), size = 1.5) +\n  geom_line(aes(y = power_2, color = \"two-tail\"), size = 1.5) +\n  scale_x_continuous(\"Sample Size\") +\n  scale_y_continuous(\"power\")+\n  ggtitle(\"Power to detect significant effect by mean\") +\n  theme_pubr() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-42-1.png){width=768}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### How can power be increased?\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#| \nggplot(data.frame(x = seq(70, 130)), aes(x)) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem)) +\n  \n  stat_function(fun = function(x) dnorm(x, m = mean, sd = sem),\n                geom = \"area\", xlim = c(cv, 130), \n                aes(fill = \"Power\"), alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, m = mean, sd = sem),\n                geom = \"area\", xlim = c(70, cv2), \n                aes(fill = \"Power\"), alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, m = mean, sd = sem),\n                geom = \"area\", xlim = c(cv2, cv), \n                aes(fill = \"Type II Error\"), alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv, 130), \n                aes(fill = \"Type I Error\"), alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, m = mu, sd = sem),\n                geom = \"area\", xlim = c(cv2, 70), \n                aes(fill = \"Type I Error\"), alpha = .5) +\n  stat_function(fun = function(x) dnorm(x, m = mean, sd = sem)) +\n  geom_vline(aes(xintercept = cv), color = \"purple\")+\n  geom_label(aes(x = mu, y = .095, label = \"H0\")) +\n  geom_label(aes(x = mean, y = .095, label = \"H1\")) +\n  geom_label(aes(x = cv, y = .1, label = \"CV\"), color = \"purple\") +\n  geom_hline(aes(yintercept = 0))+\n  scale_x_continuous(\"Means\", breaks = seq(70,130,10)) +\n  scale_y_continuous(NULL, breaks = NULL) + \n  theme_pubr() +\n  theme( text = element_text(size = 20),\n    legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](05_Hypothesis-Power_files/figure-revealjs/unnamed-chunk-43-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n$$Z_1 = \\frac{CV_0 - \\mu_1}{\\frac{\\sigma}{\\sqrt{N}}}$$\n\n::: nonincremental\n-   increase $\\mu_1$\n-   decrease $CV_0$\n-   increase $N$\n-   reduce $\\sigma$\n:::\n:::\n:::\n\n[I strongly recommend playing around with different configurations of $N$, $\\alpha$ and the difference in means ( $d$ ) in this [online demo](https://rpsychologist.com/d3/NHST/).]{style=\"font-size:30px;\"}\n\n## Calculating Power in R\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\n```\n:::\n\n\nWe will use the `pwr` package and a few tutorials you can look at are as follows:\n\n::: nonincremental\n-   [Reproducible Medical Research with R](https://bookdown.org/pdr_higgins/rmrwr/sample-size-calculations-with-pwr.html)\n-   [Stat Methods](https://www.statmethods.net/stats/power.html)\n-   [Vignettes from pwr package](https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html)\n:::\n:::\n\n::: {.column width=\"50%\"}\nThe four components are interrelated and by knowing three, we can determine the fourth:\n\n::: nonincremental\n1.  Sample Size\n2.  Effect Size\n3.  Significance Level $\\alpha$\n4.  Power $\\beta$\n:::\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Calculating Power in R: t-tests\n\n**Example:** We want to know how frustrating stats classes can be for graduate students. To do this we want to test if the mean frustration levels of students in a stats class are different than students walking around on campus. Let's say we survey 30 stats students and 30 grad students and get a \"Frustration Score\" (f-score) and then take the mean of each group.\n\nWe'll test for a difference in means using a *two-sample t-test*.\n\n***How powerful is this experiment if we want to detect a medium effect in either direction with a significance level of 0.05?***\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n::: columns\nFirst we indicate what it means to have a \"medium\" effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohen.ES(test = \"t\", size = \"medium\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Conventional effect size from Cohen (1982) \n\n           test = t\n           size = medium\n    effect.size = 0.5\n```\n:::\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n| Relative Size | Effect Size |\n|:-------------:|:-----------:|\n|     None      |     0.0     |\n|     Small     |     0.2     |\n|    Medium     |     0.5     |\n|     Large     |     0.8     |\n|  Very Large   |     1.3     |\n\n: Using *Cohen's d*\n:::\n:::\n\nFurther reading: [Sullivan, G. M., & Feinn, R. (2012). Using effect size---or why the P value is not enough. Journal of graduate medical education, 4(3), 279-282.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3444174/)\n\n------------------------------------------------------------------------\n\nThen we can use the `pwr` library to calculate the power we can expect. The function looks like:\n\n`pwr.t.test(n = , d = , sig.level = , power = , type = c(\"two.sample\", \"one.sample\", \"paired\"))`{style=\"font-size:20px;\"}\n\n::: {style=\"font-size:25px;\"}\nwhere `n` is the sample size, `d` is the effect size, `power` is the power level, and `type` indicates a two sample t-test, one sample t-test or paired t-test\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(n = 30, d = 0.5, sig.level = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 30\n              d = 0.5\n      sig.level = 0.05\n          power = 0.4778965\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n<br>Ooof...only 48%. Not very powerful.\n\n------------------------------------------------------------------------\n\nWhat if we want to get that power to the expected 80%? How many students should we collect data for?\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(d = 0.5, power = 0.80, sig.level = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 63.76561\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n<br>Looks like we would need about 64 students *per group.*\n\n------------------------------------------------------------------------\n\n## Summary\n\n-   Conducting a study we tend to have null $H_0$ and alternative $H_1$ hypotheses\n\n-   Tested through Null Hypothesis Significance Testing\n\n-   $p-values$ are the probability of getting this score or higher **if the null distribution were true**\n\n-   Important to consider power in all studies we do\n\n------------------------------------------------------------------------\n\n![](images/preg.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n## Reminders\n\n-   Lab 2 is due at 11:59pm on Sunday (10/1)\n\n-   \n\n------------------------------------------------------------------------\n\n## Additional Slides\n\n## alpha\n\nHistorically, psychologists have chosen to set their $\\alpha$ level at .05, meaning any p-value less than .05 is considered \"statistically significant\" or the null is rejected.\n\nThis means that, among the times we examine a relationship that is truly null, we will reject the null 1 in 20 times.\n\nSome have argued that this is not conservative enough and we should use $\\alpha < .005$ ([Benjamin et al., 2018](../readings/Benjamin_etal_2018.pdf)).\n\n------------------------------------------------------------------------\n\n## Check-in and Review\n\n-   The null hypothesis ( $H_0$ ) is a claim about the particular value that a population parameter takes.\n\n-   The alternative hypothesis ( $H_1$ ) states an alternative range of values for the population parameter.\n\n-   We test the null hypothesis by determining if we have sufficient evidence that contradicts or nullifies it.\n\n-   We reject the null hypothesis if the data in hand are rare, unusual, or atypical if the null were true. The alternative hypothesis gains support when the null is rejected, but $H_1$ is not proven.\n\n------------------------------------------------------------------------\n\n### Review example\n\nHealthy adults send an average of 32 text messages a day $(\\sigma = 7.3)$. I recruit a sample of 16 adults with diagnoses of Generalized Anxiety Disorder. In my sample, the average number of texts sent per day is 33.2. *Does my sample of adults with GAD come from the same population as healthy adults?*\n\n::: columns\n::: {.column width=\"50%\"}\n**Define hypotheses**\n\n-   $H_0: \\mu_{GAD} = 32$\n-   $H_0: \\mu_{GAD} \\neq 32$\n:::\n\n::: {.column width=\"50%\"}\n**Choose alpha**\n\n-   $\\alpha = .05$\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Review example\n\n**Collect data.**\n\n::: columns\n::: {.column width=\"50%\"}\n**Define your sampling distribution using your null hypothesis**\n\n-   $\\mu_M = \\mu_0 = 32$\n-   $\\sigma_M = \\frac{\\sigma}{\\sqrt{N}} = \\frac{7.3}{\\sqrt{16}} = 1.825$\n:::\n\n::: {.column width=\"50%\"}\n**Calculate the probability of your data or more extreme under the null.**\n\n-   $Z_{statistic} = \\frac{\\bar{X} - \\mu_0}{\\sigma_M} = \\frac{33.2 - 32}{1.825} = 0.658$\n-   $p(Z >= 0.658) = 0.255$\n-   $p = 0.511$\n:::\n:::\n\n------------------------------------------------------------------------\n\nCompare your probability ( $p$-value) to your $\\alpha$ level and decide whether your data are \"statistically significant\" (reject the null) or not (retain the null).\n\nOur $p$-value is larger than our $\\alpha$ level, so we retain the null.\n\n------------------------------------------------------------------------\n\n### Review\n\nIf we do not reject $H_0$, that does not mean that we accept it. We have simply failed to reject it. It lives to fight another day.\n\nA *Z*-statistic summarizes how unusual the sample estimate of a mean compared to the value of the mean as specified by the null hypothesis.\n\nMore broadly, we refer to the **test statistic** as the statistic that summarizes how unusual the sample estimate of a parameter is from the point value specified by the null hypothesis\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}