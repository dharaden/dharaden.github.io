{"title":"Categorical Data & Comparing Means","markdown":{"yaml":{"title":"Categorical Data & Comparing Means","subtitle":"PSYC 640 - Fall 2023","author":"Dustin Haraden, PhD","format":{"revealjs":{"multiplex":true,"slide-number":true,"incremental":true,"touch":true,"code-overflow":"wrap","theme":"dark"}},"execute":{"echo":true},"editor":"visual"},"headingText":"Last week","containsRefs":false,"markdown":"\n\n```{r, include = F}\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n```\n\n\n::: nonincremental\n-   Review of the NHST\n-   Categorical Data analysis with the $\\chi^2$ distribution\n    -   Goodness of Fit test\n:::\n\n```{r, results = 'hide', message = F, warning = F}\n# File management\nlibrary(here)\n# for dplyr, ggplot\nlibrary(tidyverse)\n# Descriptives\nlibrary(psych)\n# Making things look nice\nlibrary(knitr)\n# Presenting nice tables\nlibrary(kableExtra)\n# Making things look nice\nlibrary(ggpubr)\n# animate things\nlibrary(gganimate)\n\n```\n\n------------------------------------------------------------------------\n\n## Today...\n\n-   The chi-square test of independence ([Book Chapter 12.2](https://learningstatisticswithr.com/book/chisquare.html#chisqindependence))\n-   Review Assumptions of chi-square test\n-   Introduction to Comparing Means\n\n------------------------------------------------------------------------\n\n## Pop Quiz...jk {.center}\n\n-   What do we mean when we say a study was powered to an effect of 0.34?\n\n-   What does a p-value tell us?\n\n    -   [Scientists get it wrong](https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/)\n\n------------------------------------------------------------------------\n\n### $\\chi^2$ test of independence or association\n\nThe previous tests that we conducted last class, we were focused on the way our data (NY Students Superpower Preferences) \"fit\" to the data of an expected distribution (US Student Superpower Preferences)\n\nAlthough this could be interesting, sometimes we have two categorical variables that we want to compare to one another\n\n-   How do types of traffic stops differ by the gender identity of the police officer?\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\n![](/images/Planet_express.webp){fig-align=\"center\" width=\"192\"}\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\nWe have been tasked to deliver a package to Chapek 9\n\n![](/images/Chapek_9.webp){fig-align=\"center\" width=\"192\"}\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\nWe have been tasked to deliver a package to Chapek 9\n\nUnfortunately, the planet is inhabited completely by robots and humans are not allowed\n\nIn order to deliver the package, we have to go through the guard gate and prove that we are able to gain access\n\n------------------------------------------------------------------------\n\n### At the guard gate\n\n> *(Robot Voice)*\n>\n> WHICH OF THE FOLLOWING WOULD YOU MOST PREFER?\n>\n> A: A Puppy\n>\n> B: A pretty flower from your sweetie\n>\n> C: A large properly-formatted data file\n>\n> CHOOSE NOW!\n\n-   Clearly an ingenious test that will catch any imposters!\n-   ***But what if humans and robots have similar preferences?***\n\n------------------------------------------------------------------------\n\nLuckily, I have connections with Chapek 9 and we can see if there are any similarities between the responses.\n\nLet's work through how to do a $\\chi^2$ test of independence (or association)\n\nFirst, we have to load in the data:\n\n```{r}\nchapek9 <- read.csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/chapek9.csv\") %>% \n  mutate(choice = as.factor(choice), \n         species = as.factor(species))\n```\n\n------------------------------------------------------------------------\n\n## Chapek 9 Data\n\nTake a peek at the data:\n\n```{r}\nhead(chapek9)\n# or \n#glimpse(chapek9)\n```\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data\n\nLook at the summary stats for the data:\n\n```{r}\nsummary(chapek9) \n```\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data - Cross Tabs\n\nThere are a few different ways to look at these tables. We can use `xtabs()`\n\n```{r}\nchapekFreq <- xtabs( ~ choice + species, data = chapek9)\nchapekFreq\n```\n\n------------------------------------------------------------------------\n\n## Constructing Hypotheses\n\nResearch hypothesis states that \"humans and robots answer the question in different ways\"\n\nNow our notation has two subscript values?? What torture is this??\n\n![](/images/Greek_breakdown.PNG){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n## Constructing Hypotheses\n\nOnce we have this established, we can take a look at the null\n\n![](/images/Null_prob.PNG){fig-align=\"center\"}\n\n-   Claiming now that the true choice probabilities don't depend on the species making the choice ( $P_i$ )\n\n-   However, we don't know what the ***expected*** probability would be for each answer choice\n\n    -   We have to calculate the totals of each row/column\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data - Cross Tabs\n\n::: columns\n::: {.column width=\"50%\"}\nLet's use R to make the table look fancy and calculate the totals for us!\n\nWe will use the library `sjPlot` ([link](https://strengejacke.github.io/sjPlot/reference/index.html#descriptive-statistics-tables))\n\n**Note:** Will need to knit the document to get this table\n\n```{r, results='asis', message=FALSE, eval = FALSE}\n#| codefold: TRUE\n\nlibrary(sjPlot)\n\ntab_xtab(var.row = chapek9$choice, \n          var.col = chapek9$species, \n         title = \"Chapek 9 Frequencies\")\n\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r, results='asis', message=FALSE, echo=FALSE}\n\nlibrary(sjPlot)\n\ntab_xtab(var.row = chapek9$choice, \n          var.col = chapek9$species, \n         title = \"Chapek 9 Frequencies\")\n\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Note about degrees of freedom\n\nDegrees of freedom comes from the number of data points that you have, minus the number of constraints\n\n-   Using contingency tables (or cross-tabs), the data points we have are $rows * columns$\n\n-   There will be two constraints and $df = (rows-1) * (columns-1)$\n\n------------------------------------------------------------------------\n\nWe now have all the pieces for a $classic$ Null Hypothesis Significance Test\n\nBut we have these computers, so why not use them?\n\nUsing the `associationTest()` from the `lsr` library\n\n```{r}\nlsr::associationTest(formula = ~choice+species,\n                data = chapek9)\n```\n\n------------------------------------------------------------------------\n\nMaybe we want to keep it traditional and use `chisq.test()` will there be a difference?\n\n[Book Ch 12.6 - The most typical way to do a chi-square test in R](https://learningstatisticswithr.com/book/chisquare.html#chisq.test)\n\n```{r}\nchi <- chisq.test(table(chapek9$choice, chapek9$species))\nchi\n```\n\n------------------------------------------------------------------------\n\nBut what if we want to visualize it? Use `sjPlot` again\n\n```{r}\nplot_xtab(chapek9$choice, \n          chapek9$species)\n```\n\n------------------------------------------------------------------------\n\nLet's clean that up a little bit more\n\n```{r}\nplot_xtab(chapek9$choice, chapek9$species, margin = \"row\", bar.pos = \"stack\", coord.flip = TRUE)\n```\n\n------------------------------------------------------------------------\n\n## Writing it up\n\n> Pearson's $\\chi^2$ revealed a significant association between species and choice ( $\\chi^2 (2) =$ 10.7, $p$ \\< .01), such that robots appeared to be more likely to say that they prefer flowers, but the humans were more likely to say they prefer data.\n\n------------------------------------------------------------------------\n\n## Assumptions of the test\n\n-   The expected frequencies are rather large\n\n-   Data are independent of one another\n\n------------------------------------------------------------------------\n\n## Comparing Means\n\nWhen we move from categorical outcomes to variables measured on an interval or ratio scale, we become interested in means rather than frequencies. Comparing means is usually done with the *t*-test, of which there are several forms.\n\nThe one-sample *t*-test is appropriate when a single sample mean is compared to a population mean but the population standard deviation is unknown. A sample estimate of the population standard deviation is used instead. The appropriate sampling distribution is the t-distribution, with N-1 degrees of freedom.\n\n$$t_{df=N-1} = \\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}$$\n\nThe heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.\n\n------------------------------------------------------------------------\n\n## One-sample *t*-tests\n\n*t*-tests were developed by William Sealy Gosset, who was a chemist studying the grains used in making beer. (He worked for Guinness.)\n\n-   Specifically, he wanted to know whether particular strains of grain made better or worse beer than the standard.\n\n-   He developed the *t*-test, to test small samples of beer against a population with an unknown standard deviation.\n\n    -   Probably had input from Karl Pearson and Ronald Fisher\n\n-   Published this as \"Student\" because Guinness didn't want these tests tied to the production of beer.\n\n------------------------------------------------------------------------\n\n### Load in the dataset from last class\n\n```{r}\nschool <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/example2-chisq.csv\") %>% \n  mutate(Score_in_memory_game = as.numeric(Score_in_memory_game))\nschool <- school %>% \n  filter(!is.na(Score_in_memory_game))\n```\n\n------------------------------------------------------------------------\n\n### One-sample *t*-tests vs Z-test\n\n|                                             | Z-test                    | *t*-test                        |\n|-------------------|---------------------------|---------------------------|\n| $\\large{\\mu}$                               | known                     | known                           |\n| $\\sigma$                                    | known                     | unknown                         |\n| sem or $\\sigma_M$                           | $\\frac{\\sigma}{\\sqrt{N}}$ | $\\frac{\\hat{\\sigma}}{\\sqrt{N}}$ |\n| Probability distribution                    | standard normal           | $t$                             |\n| DF                                          | none                      | $N-1$                           |\n| Tails                                       | One or two                | One or two                      |\n| Critical value $(\\alpha = .05, two-tailed)$ | 1.96                      | Depends on DF                   |\n\n------------------------------------------------------------------------\n\n### **Assumptions of the one-sample *t*-test**\n\n**Normality.** We assume the sampling distribution of the mean is normally distributed. Under what two conditions can we be assured that this is true?\n\n**Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say. How can we be safe in this assumption?\n\n------------------------------------------------------------------------\n\n### A brief example\n\nUsing the same Census at School data, we find that New York students who participated in a memory game ( $N = 224$ ) completed the game in an average time of 44.2 seconds ( $s = 15.3$ ). We know that the average US student completed the game in 45.04 seconds. How do our students compare?\n\n**Hypotheses**\n\n$H_0: \\mu = 45.05$\n\n$H_1: \\mu \\neq 45.05$\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\mu = 45.05$$\n\n$$N = 227$$\n\n$$ \\bar{X} = 44.2 $$\n\n$$ s = 15.3 $$\n:::\n\n::: {.column width=\"50%\"}\n```{r}\nt.test(x = school$Score_in_memory_game, \n       mu = 45.05,\n       alternative = \"two.sided\")\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n```{r}\nlsr::oneSampleTTest(x = school$Score_in_memory_game,\n                    mu = 45.05, one.sided = FALSE)\n```\n\n------------------------------------------------------------------------\n\n## Cohen's D\n\nCohen suggested one of the most common effect size estimates---the standardized mean difference---useful when comparing a group mean to a population mean or two group means to each other.\n\n$$\\delta = \\frac{\\mu_1 - \\mu_0}{\\sigma} \\approx d = \\frac{\\bar{X}-\\mu}{\\hat{\\sigma}}$$\n\nCohen's d is in the standard deviation (Z) metric.\n\n------------------------------------------------------------------------\n\nCohens's d for these data is .05. In other words, the sample mean differs from the population mean by .05 standard deviation units.\n\nCohen (1988) suggests the following guidelines for interpreting the size of d:\n\n::: nonincremental\n-   .2 = Small\n\n-   .5 = Medium\n\n-   .8 = Large\n:::\n\n[Cohen, J. (1988), Statistical power analysis for the behavioral sciences (2nd Ed.). Hillsdale: Lawrence Erlbaum.]{style=\"font-size:30px;\"}\n\n------------------------------------------------------------------------\n\n### The usefulness of the one-sample *t*-test\n\nHow often will you conducted a one-sample *t*-test on raw data?\n\n-   (Probably) never\n\nHow often will you come across one-sample *t*-tests?\n\n-   (Probably) a lot!\n\nThe one-sample *t*-test is used to test coefficients in a model.\n\n------------------------------------------------------------------------\n\n```{r}\n#Load sleep data: https://vincentarelbundock.github.io/Rdatasets/datasets.html\nsleep <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/sleepstudy.csv\")\nmodel = lm(Reaction ~ Days, data = sleep)\nsummary(model)\n```\n\n------------------------------------------------------------------------\n\n## Next time...\n\nMore comparing means!\n\n# Reminders\n\nNo Class 10/9\n\nNo Office Hours tomorrow (10/5)\n\nNext lab will likely begin on 10/16\n","srcMarkdownNoYaml":"\n\n```{r, include = F}\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n```\n\n## Last week\n\n::: nonincremental\n-   Review of the NHST\n-   Categorical Data analysis with the $\\chi^2$ distribution\n    -   Goodness of Fit test\n:::\n\n```{r, results = 'hide', message = F, warning = F}\n# File management\nlibrary(here)\n# for dplyr, ggplot\nlibrary(tidyverse)\n# Descriptives\nlibrary(psych)\n# Making things look nice\nlibrary(knitr)\n# Presenting nice tables\nlibrary(kableExtra)\n# Making things look nice\nlibrary(ggpubr)\n# animate things\nlibrary(gganimate)\n\n```\n\n------------------------------------------------------------------------\n\n## Today...\n\n-   The chi-square test of independence ([Book Chapter 12.2](https://learningstatisticswithr.com/book/chisquare.html#chisqindependence))\n-   Review Assumptions of chi-square test\n-   Introduction to Comparing Means\n\n------------------------------------------------------------------------\n\n## Pop Quiz...jk {.center}\n\n-   What do we mean when we say a study was powered to an effect of 0.34?\n\n-   What does a p-value tell us?\n\n    -   [Scientists get it wrong](https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/)\n\n------------------------------------------------------------------------\n\n### $\\chi^2$ test of independence or association\n\nThe previous tests that we conducted last class, we were focused on the way our data (NY Students Superpower Preferences) \"fit\" to the data of an expected distribution (US Student Superpower Preferences)\n\nAlthough this could be interesting, sometimes we have two categorical variables that we want to compare to one another\n\n-   How do types of traffic stops differ by the gender identity of the police officer?\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\n![](/images/Planet_express.webp){fig-align=\"center\" width=\"192\"}\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\nWe have been tasked to deliver a package to Chapek 9\n\n![](/images/Chapek_9.webp){fig-align=\"center\" width=\"192\"}\n\n------------------------------------------------------------------------\n\nLet's take a look at a scenario:\n\nWe are part of a delivery company called Planet Express\n\nWe have been tasked to deliver a package to Chapek 9\n\nUnfortunately, the planet is inhabited completely by robots and humans are not allowed\n\nIn order to deliver the package, we have to go through the guard gate and prove that we are able to gain access\n\n------------------------------------------------------------------------\n\n### At the guard gate\n\n> *(Robot Voice)*\n>\n> WHICH OF THE FOLLOWING WOULD YOU MOST PREFER?\n>\n> A: A Puppy\n>\n> B: A pretty flower from your sweetie\n>\n> C: A large properly-formatted data file\n>\n> CHOOSE NOW!\n\n-   Clearly an ingenious test that will catch any imposters!\n-   ***But what if humans and robots have similar preferences?***\n\n------------------------------------------------------------------------\n\nLuckily, I have connections with Chapek 9 and we can see if there are any similarities between the responses.\n\nLet's work through how to do a $\\chi^2$ test of independence (or association)\n\nFirst, we have to load in the data:\n\n```{r}\nchapek9 <- read.csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/chapek9.csv\") %>% \n  mutate(choice = as.factor(choice), \n         species = as.factor(species))\n```\n\n------------------------------------------------------------------------\n\n## Chapek 9 Data\n\nTake a peek at the data:\n\n```{r}\nhead(chapek9)\n# or \n#glimpse(chapek9)\n```\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data\n\nLook at the summary stats for the data:\n\n```{r}\nsummary(chapek9) \n```\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data - Cross Tabs\n\nThere are a few different ways to look at these tables. We can use `xtabs()`\n\n```{r}\nchapekFreq <- xtabs( ~ choice + species, data = chapek9)\nchapekFreq\n```\n\n------------------------------------------------------------------------\n\n## Constructing Hypotheses\n\nResearch hypothesis states that \"humans and robots answer the question in different ways\"\n\nNow our notation has two subscript values?? What torture is this??\n\n![](/images/Greek_breakdown.PNG){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n## Constructing Hypotheses\n\nOnce we have this established, we can take a look at the null\n\n![](/images/Null_prob.PNG){fig-align=\"center\"}\n\n-   Claiming now that the true choice probabilities don't depend on the species making the choice ( $P_i$ )\n\n-   However, we don't know what the ***expected*** probability would be for each answer choice\n\n    -   We have to calculate the totals of each row/column\n\n------------------------------------------------------------------------\n\n### Chapek 9 Data - Cross Tabs\n\n::: columns\n::: {.column width=\"50%\"}\nLet's use R to make the table look fancy and calculate the totals for us!\n\nWe will use the library `sjPlot` ([link](https://strengejacke.github.io/sjPlot/reference/index.html#descriptive-statistics-tables))\n\n**Note:** Will need to knit the document to get this table\n\n```{r, results='asis', message=FALSE, eval = FALSE}\n#| codefold: TRUE\n\nlibrary(sjPlot)\n\ntab_xtab(var.row = chapek9$choice, \n          var.col = chapek9$species, \n         title = \"Chapek 9 Frequencies\")\n\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r, results='asis', message=FALSE, echo=FALSE}\n\nlibrary(sjPlot)\n\ntab_xtab(var.row = chapek9$choice, \n          var.col = chapek9$species, \n         title = \"Chapek 9 Frequencies\")\n\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n### Note about degrees of freedom\n\nDegrees of freedom comes from the number of data points that you have, minus the number of constraints\n\n-   Using contingency tables (or cross-tabs), the data points we have are $rows * columns$\n\n-   There will be two constraints and $df = (rows-1) * (columns-1)$\n\n------------------------------------------------------------------------\n\nWe now have all the pieces for a $classic$ Null Hypothesis Significance Test\n\nBut we have these computers, so why not use them?\n\nUsing the `associationTest()` from the `lsr` library\n\n```{r}\nlsr::associationTest(formula = ~choice+species,\n                data = chapek9)\n```\n\n------------------------------------------------------------------------\n\nMaybe we want to keep it traditional and use `chisq.test()` will there be a difference?\n\n[Book Ch 12.6 - The most typical way to do a chi-square test in R](https://learningstatisticswithr.com/book/chisquare.html#chisq.test)\n\n```{r}\nchi <- chisq.test(table(chapek9$choice, chapek9$species))\nchi\n```\n\n------------------------------------------------------------------------\n\nBut what if we want to visualize it? Use `sjPlot` again\n\n```{r}\nplot_xtab(chapek9$choice, \n          chapek9$species)\n```\n\n------------------------------------------------------------------------\n\nLet's clean that up a little bit more\n\n```{r}\nplot_xtab(chapek9$choice, chapek9$species, margin = \"row\", bar.pos = \"stack\", coord.flip = TRUE)\n```\n\n------------------------------------------------------------------------\n\n## Writing it up\n\n> Pearson's $\\chi^2$ revealed a significant association between species and choice ( $\\chi^2 (2) =$ 10.7, $p$ \\< .01), such that robots appeared to be more likely to say that they prefer flowers, but the humans were more likely to say they prefer data.\n\n------------------------------------------------------------------------\n\n## Assumptions of the test\n\n-   The expected frequencies are rather large\n\n-   Data are independent of one another\n\n------------------------------------------------------------------------\n\n## Comparing Means\n\nWhen we move from categorical outcomes to variables measured on an interval or ratio scale, we become interested in means rather than frequencies. Comparing means is usually done with the *t*-test, of which there are several forms.\n\nThe one-sample *t*-test is appropriate when a single sample mean is compared to a population mean but the population standard deviation is unknown. A sample estimate of the population standard deviation is used instead. The appropriate sampling distribution is the t-distribution, with N-1 degrees of freedom.\n\n$$t_{df=N-1} = \\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}$$\n\nThe heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.\n\n------------------------------------------------------------------------\n\n## One-sample *t*-tests\n\n*t*-tests were developed by William Sealy Gosset, who was a chemist studying the grains used in making beer. (He worked for Guinness.)\n\n-   Specifically, he wanted to know whether particular strains of grain made better or worse beer than the standard.\n\n-   He developed the *t*-test, to test small samples of beer against a population with an unknown standard deviation.\n\n    -   Probably had input from Karl Pearson and Ronald Fisher\n\n-   Published this as \"Student\" because Guinness didn't want these tests tied to the production of beer.\n\n------------------------------------------------------------------------\n\n### Load in the dataset from last class\n\n```{r}\nschool <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/example2-chisq.csv\") %>% \n  mutate(Score_in_memory_game = as.numeric(Score_in_memory_game))\nschool <- school %>% \n  filter(!is.na(Score_in_memory_game))\n```\n\n------------------------------------------------------------------------\n\n### One-sample *t*-tests vs Z-test\n\n|                                             | Z-test                    | *t*-test                        |\n|-------------------|---------------------------|---------------------------|\n| $\\large{\\mu}$                               | known                     | known                           |\n| $\\sigma$                                    | known                     | unknown                         |\n| sem or $\\sigma_M$                           | $\\frac{\\sigma}{\\sqrt{N}}$ | $\\frac{\\hat{\\sigma}}{\\sqrt{N}}$ |\n| Probability distribution                    | standard normal           | $t$                             |\n| DF                                          | none                      | $N-1$                           |\n| Tails                                       | One or two                | One or two                      |\n| Critical value $(\\alpha = .05, two-tailed)$ | 1.96                      | Depends on DF                   |\n\n------------------------------------------------------------------------\n\n### **Assumptions of the one-sample *t*-test**\n\n**Normality.** We assume the sampling distribution of the mean is normally distributed. Under what two conditions can we be assured that this is true?\n\n**Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say. How can we be safe in this assumption?\n\n------------------------------------------------------------------------\n\n### A brief example\n\nUsing the same Census at School data, we find that New York students who participated in a memory game ( $N = 224$ ) completed the game in an average time of 44.2 seconds ( $s = 15.3$ ). We know that the average US student completed the game in 45.04 seconds. How do our students compare?\n\n**Hypotheses**\n\n$H_0: \\mu = 45.05$\n\n$H_1: \\mu \\neq 45.05$\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\mu = 45.05$$\n\n$$N = 227$$\n\n$$ \\bar{X} = 44.2 $$\n\n$$ s = 15.3 $$\n:::\n\n::: {.column width=\"50%\"}\n```{r}\nt.test(x = school$Score_in_memory_game, \n       mu = 45.05,\n       alternative = \"two.sided\")\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n```{r}\nlsr::oneSampleTTest(x = school$Score_in_memory_game,\n                    mu = 45.05, one.sided = FALSE)\n```\n\n------------------------------------------------------------------------\n\n## Cohen's D\n\nCohen suggested one of the most common effect size estimates---the standardized mean difference---useful when comparing a group mean to a population mean or two group means to each other.\n\n$$\\delta = \\frac{\\mu_1 - \\mu_0}{\\sigma} \\approx d = \\frac{\\bar{X}-\\mu}{\\hat{\\sigma}}$$\n\nCohen's d is in the standard deviation (Z) metric.\n\n------------------------------------------------------------------------\n\nCohens's d for these data is .05. In other words, the sample mean differs from the population mean by .05 standard deviation units.\n\nCohen (1988) suggests the following guidelines for interpreting the size of d:\n\n::: nonincremental\n-   .2 = Small\n\n-   .5 = Medium\n\n-   .8 = Large\n:::\n\n[Cohen, J. (1988), Statistical power analysis for the behavioral sciences (2nd Ed.). Hillsdale: Lawrence Erlbaum.]{style=\"font-size:30px;\"}\n\n------------------------------------------------------------------------\n\n### The usefulness of the one-sample *t*-test\n\nHow often will you conducted a one-sample *t*-test on raw data?\n\n-   (Probably) never\n\nHow often will you come across one-sample *t*-tests?\n\n-   (Probably) a lot!\n\nThe one-sample *t*-test is used to test coefficients in a model.\n\n------------------------------------------------------------------------\n\n```{r}\n#Load sleep data: https://vincentarelbundock.github.io/Rdatasets/datasets.html\nsleep <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/sleepstudy.csv\")\nmodel = lm(Reaction ~ Days, data = sleep)\nsummary(model)\n```\n\n------------------------------------------------------------------------\n\n## Next time...\n\nMore comparing means!\n\n# Reminders\n\nNo Class 10/9\n\nNo Office Hours tomorrow (10/5)\n\nNext lab will likely begin on 10/16\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"06_OneSample2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.433","auto-stretch":true,"editor":"visual","title":"Categorical Data & Comparing Means","subtitle":"PSYC 640 - Fall 2023","author":"Dustin Haraden, PhD","multiplex":true,"slideNumber":true,"touch":true,"theme":"dark"}}},"projectFormats":["html"]}