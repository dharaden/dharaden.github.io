{"title":"Comparing Means: t-tests","markdown":{"yaml":{"title":"Comparing Means: t-tests","subtitle":"PSYC 640 - Fall 2023","author":"Dustin Haraden, PhD","format":{"revealjs":{"multiplex":true,"slide-number":true,"incremental":true,"touch":true,"code-overflow":"wrap","theme":"dark"}},"execute":{"echo":true},"editor":"visual","editor_options":{"chunk_output_type":"console"}},"headingText":"Last week","containsRefs":false,"markdown":"\n\n```{r, include = F}\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n```\n\n\n::: nonincremental\n-   Categorical Data analysis with the $\\chi^2$ distribution\n    -   Test of Independence & Goodness of Fit Test\n-   Single Sample $t$-test\n:::\n\n```{r, results = 'hide', message = F, warning = F}\nlibrary(lsr)\n# File management\nlibrary(here)\n# for dplyr, ggplot\nlibrary(tidyverse)\n# Making things look nice\nlibrary(ggpubr)\n#Loading data\nlibrary(rio)\n# Assumption Checks\nlibrary(car)\n\n#Remove Scientific Notation \noptions(scipen=999)\n\n```\n\n------------------------------------------------------------------------\n\n## Today...\n\n-   Comparing Means with the $t$-test\n    -   Independent samples\n    -   Paired Samples (probably next class)\n\n------------------------------------------------------------------------\n\n## Comparing Means\n\nCalculated using a t-test. To calculate the t-statistic, you will use this formula:\n\n$$t_{df=N-1} = \\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}$$\n\nThe heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.\n\n------------------------------------------------------------------------\n\n### Load in the dataset from last class\n\n```{r}\nschool <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/example2-chisq.csv\") %>%  \n  mutate(Score_in_memory_game = as.numeric(Score_in_memory_game))\nschool <- school %>% \n  filter(!is.na(Score_in_memory_game))\n```\n\n------------------------------------------------------------------------\n\n### One-sample *t*-tests vs Z-test\n\n| Parameters                                  | Z-test                    | *t*-test                        |\n|-------------------------------|-------------------|-----------------------|\n| $\\large{\\mu}$                               | known                     | known                           |\n| $\\sigma$                                    | known                     | unknown                         |\n| sem or $\\sigma_M$                           | $\\frac{\\sigma}{\\sqrt{N}}$ | $\\frac{\\hat{\\sigma}}{\\sqrt{N}}$ |\n| Probability distribution                    | standard normal           | $t$                             |\n| DF                                          | none                      | $N-1$                           |\n| Tails                                       | One or two                | One or two                      |\n| Critical value $(\\alpha = .05, two-tailed)$ | 1.96                      | Depends on DF                   |\n\n------------------------------------------------------------------------\n\n### **Assumptions of the one-sample *t*-test**\n\n-   **Normality.** We assume the sampling distribution of the mean is normally distributed. Under what two conditions can we be assured that this is true?\n\n-   **Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say. How can we be safe in this assumption?\n\n------------------------------------------------------------------------\n\n### A brief example - REVIEW\n\nUsing the same Census at School data, we find that New York students who participated in a memory game ( $N = 224$ ) completed the game in an average time of 44.2 seconds ( $s = 15.3$ ). We know that the average US student completed the game in 45.04 seconds. How do our students compare? <br>\n\n<br>\n\n**Hypotheses**\n\n$H_0: \\mu = 45.05$\n\n$H_1: \\mu \\neq 45.05$\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\mu = 45.05$$\n\n$$N = 227$$\n\n$$ \\bar{X} = 44.2 $$\n\n$$ s = 15.3 $$\n\n$$\n\\sigma = Unknown\n$$\n:::\n\n::: {.column width=\"50%\"}\n```{r}\nt.test(x = school$Score_in_memory_game, \n       mu = 45.05,\n       alternative = \"two.sided\")\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n```{r}\nlsr::oneSampleTTest(x = school$Score_in_memory_game,\n                    mu = 45.05, one.sided = FALSE)\n```\n\n------------------------------------------------------------------------\n\n## Writing Up a t-test\n\n> \"A one-sample t-test was conducted to determine if the mean \\[variable name\\] differed from a hypothesized population mean of \\[population mean\\]. The sample mean was M = \\[sample mean\\], which was significantly \\[greater than/less than/different from\\] the hypothesized population mean, t(df) = \\[t-value\\], p = \\[p-value\\].\"\n\nA one-sample t-test was conducted to determine if the mean score in a memory game for NY students differed from the US population mean. The sample mean was $M = 44.164$ (SD = 15.32, CI = \\[42.15, 46.18\\]), which was not significantly different from the population mean, $t(223) = -0.87$, $p = 0.388$.\n\n------------------------------------------------------------------------\n\nSingle sample t-tests are not used super often in practice\n\nYou will mainly see them when interpreting effect sizes of coefficients in your model\n\n```{r}\n#Load sleep data: https://vincentarelbundock.github.io/Rdatasets/datasets.html\nsleep <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/sleepstudy.csv\")\nmodel = lm(Reaction ~ Days, data = sleep)\nsummary(model)\n```\n\n------------------------------------------------------------------------\n\n## Types of t-Tests\n\nSingle Samples t-test\n\nIndependent Samples t-test\n\nPaired Samples t-test\n\n------------------------------------------------------------------------\n\n## Types of t-Tests: Assumptions\n\n~~Single Samples t-test~~\n\nIndependent Samples t-test\n\n::: columns\n::: {.column width=\"50%\"}\n-   Random Sampling\n\n-   Independent observations\n:::\n\n::: {.column width=\"50%\"}\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n:::\n:::\n\nPaired Samples t-test\n\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n\n------------------------------------------------------------------------\n\n## Dataset\n\nMoving forward for today, we will use this dataset\n\n::: nonincremental\n-   100 students from New York\n\n-   100 students from New Mexico\n:::\n\n```{r}\n\nstate_school <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/NM-NY_CAS.csv\")\n\n```\n\n## Normality Assumption\n\n1.  **Check for Normality**: Visualizing data (histograms), Q-Q plots, and statistical tests (Shapiro-Wilk, Anderson-Darling) to assess normality.\n\n2.  **Remedies for Violations**: data transformation or non-parametric alternatives when data is not normally distributed.\n\n------------------------------------------------------------------------\n\n### Normality Assumption - Visualizing\n\nVisualizing Data\n\n```{r}\nhist(as.numeric(state_school$Sleep_Hours_Schoolnight))\n\n```\n\n------------------------------------------------------------------------\n\nLet's make it pretty\n\n```{r}\nstate_school %>% \n  ggplot(aes(Sleep_Hours_Schoolnight,\n             fill = Region)) +\n  geom_bar(position = \"dodge\")\n\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Q-Q Plot\n\nA Q-Q plot is a graphical method for assessing whether a dataset follows a normal distribution. It compares the quantiles of your data to the quantiles of a theoretical normal distribution. If your data follows a normal distribution, the points in the Q-Q plot should form a straight line.\n\n```{r}\nqqPlot(state_school$Sleep_Hours_Schoolnight)\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Shapiro-Wilk Test\n\nExamines the Null Hypothesis that the data are normally distributed\n\n```{r}\nshapiro.test(state_school$Sleep_Hours_Schoolnight)\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption\n\n-   Strict adherence to normality assumptions is not always necessary,\n\n    -   Larger samples bring in Central Limit Theorem\n\n-   However, assessing normality is still a valuable step in understanding distributions and potential impacts on your analyses\n\n------------------------------------------------------------------------\n\n### Failure of Normality Assumptions\n\nWhat can we do if our data violate these normality assumptions?\n\n-   Logarithmic Transformations\n\n-   Square Root Transformations\n\n-   Non-parametric tests\n\n    -   **Mann-Whitney U Test (Wilcoxon Rank-Sum Test):** Used for comparing two independent groups\n\n    <!-- -->\n\n    -   **Wilcoxon Signed-Rank Test:** Used for comparing two paired or matched groups\n\n------------------------------------------------------------------------\n\n## Homogeneity of Variance\n\n1.  **Check for Equality of Variances**: Levene's test to assess if variances are equal between groups\n\n2.  **Remedies for Violations**: Welch's t-test for unequal variances.\n\n------------------------------------------------------------------------\n\n### Levene's Test\n\nThis test is used to examine if the variance is equal across groups. The Null Hypothesis is that the variances are equal\n\n```{r}\n# Perform Levene's test for equality of variances\nleveneTest(Sleep_Hours_Schoolnight ~ Region, \n           data = state_school)\n```\n\n::: {style=\"font-size: 30px\"}\nLike other tests of significance, Levene's test gets more powerful as sample size increases. So unless your two variances are exactly equal to each other (and if they are, you don't need to do a test), your test will be \"significant\" with a large enough sample. Part of the analysis has to be an eyeball test -- is this \"significant\" because they are truly different, or because I have many subjects.\n:::\n\n# Independent Samples t-test\n\n[Chapter 13.3 in Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#studentttest)\n\nTwo different types: Student's & Welch's\n\n-   Start with Student's t-test which assumes equal variances between the groups\n\n$$\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{SE(\\bar{X_1} - \\bar{X_2})}\n$$\n\n------------------------------------------------------------------------\n\n## Student's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/student_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Student's t-test: Calculate SE\n\nAre able to use a pooled variance estimate\n\nBoth variances/standard deviations are assumed to be equal\n\nTherefore:\n\n$$\nSE(\\bar{X_1} - \\bar{X_2}) = \\hat{\\sigma} \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}\n$$\n\nWe are calculating the **Standard Error of the Difference between means**\n\nDegrees of Freedom: Total N - 2\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R\n\nUsing the `independentSamplesTest()` within the `lsr` library (make sure it is installed) we can run the test *very* easily\n\nFormula is outcome \\~ group\n\n```{r}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE #default is FALSE\n)\n\n```\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function. It doesn't look as nice, but you will likely encounter it when searching for help\n\n```{r}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE\n)\n```\n\n------------------------------------------------------------------------\n\n### Student's t-test: Write-up\n\nThe mean amount of sleep in New Mexico for youth was 6.989 (SD = 1.379), while the mean in New York was 6.994 (SD = 1.512). A Student's independent samples t-test showed that there was not a significant mean difference (*t*(180)=-0.024, *p*=.981, $CI_{95}$=\\[-0.43, 0.42\\], *d*=.004). This suggests that there is no difference between youth in NM and NY on amount of sleep on school nights.\n\n------------------------------------------------------------------------\n\n```{r}\n#https://indrajeetpatil.github.io/ggstatsplot/\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n------------------------------------------------------------------------\n\n## Welch's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/welch_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: Calculate SE\n\nSince the variances are not equal, we have to estimate the SE differently\n\n$$ SE(\\bar{X_1} - \\bar{X_2}) = \\sqrt{\\frac{\\hat{\\sigma_1^2}}{N_1} + \\frac{\\hat{\\sigma_2^2}}{N_2}} $$\n\nDegrees of Freedom is also very different:\n\n![](/images/welch_df.png){fig-align=\"center\" width=\"380\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R\n\nWe use the same function as before, but specify that the variances are not equal\n\n```{r}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function...turns out it is pretty straightforward\n\n```{r}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n------------------------------------------------------------------------\n\n## Cool Visualizations\n\nThe library [ggstatsplot](https://indrajeetpatil.github.io/ggstatsplot/) has some wonderful visualizations of various tests\n\n```{r}\n#| code-fold: true\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n# In-Class Lab\n\nTake a look at the data in `state_school` and identify another Independent Samples t-test that you can perform\n\n::: nonincremental\n-   Be sure to select (1) a grouping variable and (2) a continuous variable to look at differences between the groups\n:::\n\nFollow the steps that we went through today:\n\n::: nonincremental\n1.  Check for Normality of the variable\n2.  Check for Homogeneity of Variances\n3.  Perform the appropriate t-test\n4.  Report Results\n:::\n\n**Knit the document**\n\n------------------------------------------------------------------------\n\n## Next Time...\n\nPaired Samples t-test\n\n# Paired Samples t-Test in R\n\n[Chapter 13.5 - Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#pairedsamplesttest)\n\nAlso called \"Dependent Samples t-test\"\n\n-   We have been testing means between two *independent* samples. Participants may be randomly assigned to the separate groups\n\n    -   This is limited to those types of study designs, but what if we have repeated measures?\n\n-   We will then need to compare scores across people...the samples we are comparing now *depend* on one another and are *paired*\n\n------------------------------------------------------------------------\n\n# Common Mistakes and Pitfalls\n\n-   **Misinterpreting p-Values**\n\n-   **Violations of Assumptions**\n\n-   **Sample Size Considerations**\n\n-   **Multiple Testing Issues**\n\n------------------------------------------------------------------------\n\n## Next time...\n","srcMarkdownNoYaml":"\n\n```{r, include = F}\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n```\n\n## Last week\n\n::: nonincremental\n-   Categorical Data analysis with the $\\chi^2$ distribution\n    -   Test of Independence & Goodness of Fit Test\n-   Single Sample $t$-test\n:::\n\n```{r, results = 'hide', message = F, warning = F}\nlibrary(lsr)\n# File management\nlibrary(here)\n# for dplyr, ggplot\nlibrary(tidyverse)\n# Making things look nice\nlibrary(ggpubr)\n#Loading data\nlibrary(rio)\n# Assumption Checks\nlibrary(car)\n\n#Remove Scientific Notation \noptions(scipen=999)\n\n```\n\n------------------------------------------------------------------------\n\n## Today...\n\n-   Comparing Means with the $t$-test\n    -   Independent samples\n    -   Paired Samples (probably next class)\n\n------------------------------------------------------------------------\n\n## Comparing Means\n\nCalculated using a t-test. To calculate the t-statistic, you will use this formula:\n\n$$t_{df=N-1} = \\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}$$\n\nThe heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.\n\n------------------------------------------------------------------------\n\n### Load in the dataset from last class\n\n```{r}\nschool <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/example2-chisq.csv\") %>%  \n  mutate(Score_in_memory_game = as.numeric(Score_in_memory_game))\nschool <- school %>% \n  filter(!is.na(Score_in_memory_game))\n```\n\n------------------------------------------------------------------------\n\n### One-sample *t*-tests vs Z-test\n\n| Parameters                                  | Z-test                    | *t*-test                        |\n|-------------------------------|-------------------|-----------------------|\n| $\\large{\\mu}$                               | known                     | known                           |\n| $\\sigma$                                    | known                     | unknown                         |\n| sem or $\\sigma_M$                           | $\\frac{\\sigma}{\\sqrt{N}}$ | $\\frac{\\hat{\\sigma}}{\\sqrt{N}}$ |\n| Probability distribution                    | standard normal           | $t$                             |\n| DF                                          | none                      | $N-1$                           |\n| Tails                                       | One or two                | One or two                      |\n| Critical value $(\\alpha = .05, two-tailed)$ | 1.96                      | Depends on DF                   |\n\n------------------------------------------------------------------------\n\n### **Assumptions of the one-sample *t*-test**\n\n-   **Normality.** We assume the sampling distribution of the mean is normally distributed. Under what two conditions can we be assured that this is true?\n\n-   **Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say. How can we be safe in this assumption?\n\n------------------------------------------------------------------------\n\n### A brief example - REVIEW\n\nUsing the same Census at School data, we find that New York students who participated in a memory game ( $N = 224$ ) completed the game in an average time of 44.2 seconds ( $s = 15.3$ ). We know that the average US student completed the game in 45.04 seconds. How do our students compare? <br>\n\n<br>\n\n**Hypotheses**\n\n$H_0: \\mu = 45.05$\n\n$H_1: \\mu \\neq 45.05$\n\n------------------------------------------------------------------------\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\mu = 45.05$$\n\n$$N = 227$$\n\n$$ \\bar{X} = 44.2 $$\n\n$$ s = 15.3 $$\n\n$$\n\\sigma = Unknown\n$$\n:::\n\n::: {.column width=\"50%\"}\n```{r}\nt.test(x = school$Score_in_memory_game, \n       mu = 45.05,\n       alternative = \"two.sided\")\n```\n:::\n:::\n\n------------------------------------------------------------------------\n\n```{r}\nlsr::oneSampleTTest(x = school$Score_in_memory_game,\n                    mu = 45.05, one.sided = FALSE)\n```\n\n------------------------------------------------------------------------\n\n## Writing Up a t-test\n\n> \"A one-sample t-test was conducted to determine if the mean \\[variable name\\] differed from a hypothesized population mean of \\[population mean\\]. The sample mean was M = \\[sample mean\\], which was significantly \\[greater than/less than/different from\\] the hypothesized population mean, t(df) = \\[t-value\\], p = \\[p-value\\].\"\n\nA one-sample t-test was conducted to determine if the mean score in a memory game for NY students differed from the US population mean. The sample mean was $M = 44.164$ (SD = 15.32, CI = \\[42.15, 46.18\\]), which was not significantly different from the population mean, $t(223) = -0.87$, $p = 0.388$.\n\n------------------------------------------------------------------------\n\nSingle sample t-tests are not used super often in practice\n\nYou will mainly see them when interpreting effect sizes of coefficients in your model\n\n```{r}\n#Load sleep data: https://vincentarelbundock.github.io/Rdatasets/datasets.html\nsleep <- read_csv(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/sleepstudy.csv\")\nmodel = lm(Reaction ~ Days, data = sleep)\nsummary(model)\n```\n\n------------------------------------------------------------------------\n\n## Types of t-Tests\n\nSingle Samples t-test\n\nIndependent Samples t-test\n\nPaired Samples t-test\n\n------------------------------------------------------------------------\n\n## Types of t-Tests: Assumptions\n\n~~Single Samples t-test~~\n\nIndependent Samples t-test\n\n::: columns\n::: {.column width=\"50%\"}\n-   Random Sampling\n\n-   Independent observations\n:::\n\n::: {.column width=\"50%\"}\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n:::\n:::\n\nPaired Samples t-test\n\n-   Approximately normal distributions\n\n-   Homogeneity of variances\n\n------------------------------------------------------------------------\n\n## Dataset\n\nMoving forward for today, we will use this dataset\n\n::: nonincremental\n-   100 students from New York\n\n-   100 students from New Mexico\n:::\n\n```{r}\n\nstate_school <- import(\"https://raw.githubusercontent.com/dharaden/dharaden.github.io/main/courses/PSYC640_fall23/data/NM-NY_CAS.csv\")\n\n```\n\n## Normality Assumption\n\n1.  **Check for Normality**: Visualizing data (histograms), Q-Q plots, and statistical tests (Shapiro-Wilk, Anderson-Darling) to assess normality.\n\n2.  **Remedies for Violations**: data transformation or non-parametric alternatives when data is not normally distributed.\n\n------------------------------------------------------------------------\n\n### Normality Assumption - Visualizing\n\nVisualizing Data\n\n```{r}\nhist(as.numeric(state_school$Sleep_Hours_Schoolnight))\n\n```\n\n------------------------------------------------------------------------\n\nLet's make it pretty\n\n```{r}\nstate_school %>% \n  ggplot(aes(Sleep_Hours_Schoolnight,\n             fill = Region)) +\n  geom_bar(position = \"dodge\")\n\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Q-Q Plot\n\nA Q-Q plot is a graphical method for assessing whether a dataset follows a normal distribution. It compares the quantiles of your data to the quantiles of a theoretical normal distribution. If your data follows a normal distribution, the points in the Q-Q plot should form a straight line.\n\n```{r}\nqqPlot(state_school$Sleep_Hours_Schoolnight)\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption --- Shapiro-Wilk Test\n\nExamines the Null Hypothesis that the data are normally distributed\n\n```{r}\nshapiro.test(state_school$Sleep_Hours_Schoolnight)\n```\n\n------------------------------------------------------------------------\n\n### Normality Assumption\n\n-   Strict adherence to normality assumptions is not always necessary,\n\n    -   Larger samples bring in Central Limit Theorem\n\n-   However, assessing normality is still a valuable step in understanding distributions and potential impacts on your analyses\n\n------------------------------------------------------------------------\n\n### Failure of Normality Assumptions\n\nWhat can we do if our data violate these normality assumptions?\n\n-   Logarithmic Transformations\n\n-   Square Root Transformations\n\n-   Non-parametric tests\n\n    -   **Mann-Whitney U Test (Wilcoxon Rank-Sum Test):** Used for comparing two independent groups\n\n    <!-- -->\n\n    -   **Wilcoxon Signed-Rank Test:** Used for comparing two paired or matched groups\n\n------------------------------------------------------------------------\n\n## Homogeneity of Variance\n\n1.  **Check for Equality of Variances**: Levene's test to assess if variances are equal between groups\n\n2.  **Remedies for Violations**: Welch's t-test for unequal variances.\n\n------------------------------------------------------------------------\n\n### Levene's Test\n\nThis test is used to examine if the variance is equal across groups. The Null Hypothesis is that the variances are equal\n\n```{r}\n# Perform Levene's test for equality of variances\nleveneTest(Sleep_Hours_Schoolnight ~ Region, \n           data = state_school)\n```\n\n::: {style=\"font-size: 30px\"}\nLike other tests of significance, Levene's test gets more powerful as sample size increases. So unless your two variances are exactly equal to each other (and if they are, you don't need to do a test), your test will be \"significant\" with a large enough sample. Part of the analysis has to be an eyeball test -- is this \"significant\" because they are truly different, or because I have many subjects.\n:::\n\n# Independent Samples t-test\n\n[Chapter 13.3 in Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#studentttest)\n\nTwo different types: Student's & Welch's\n\n-   Start with Student's t-test which assumes equal variances between the groups\n\n$$\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{SE(\\bar{X_1} - \\bar{X_2})}\n$$\n\n------------------------------------------------------------------------\n\n## Student's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/student_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Student's t-test: Calculate SE\n\nAre able to use a pooled variance estimate\n\nBoth variances/standard deviations are assumed to be equal\n\nTherefore:\n\n$$\nSE(\\bar{X_1} - \\bar{X_2}) = \\hat{\\sigma} \\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}\n$$\n\nWe are calculating the **Standard Error of the Difference between means**\n\nDegrees of Freedom: Total N - 2\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R\n\nUsing the `independentSamplesTest()` within the `lsr` library (make sure it is installed) we can run the test *very* easily\n\nFormula is outcome \\~ group\n\n```{r}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE #default is FALSE\n)\n\n```\n\n------------------------------------------------------------------------\n\n### Student's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function. It doesn't look as nice, but you will likely encounter it when searching for help\n\n```{r}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = TRUE\n)\n```\n\n------------------------------------------------------------------------\n\n### Student's t-test: Write-up\n\nThe mean amount of sleep in New Mexico for youth was 6.989 (SD = 1.379), while the mean in New York was 6.994 (SD = 1.512). A Student's independent samples t-test showed that there was not a significant mean difference (*t*(180)=-0.024, *p*=.981, $CI_{95}$=\\[-0.43, 0.42\\], *d*=.004). This suggests that there is no difference between youth in NM and NY on amount of sleep on school nights.\n\n------------------------------------------------------------------------\n\n```{r}\n#https://indrajeetpatil.github.io/ggstatsplot/\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n------------------------------------------------------------------------\n\n## Welch's t-test\n\n$$\nH_0 : \\mu_1 = \\mu_2  \\ \\  H_1 : \\mu_1 \\neq \\mu_2\n$$\n\n![](/images/welch_H.png){fig-align=\"center\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: Calculate SE\n\nSince the variances are not equal, we have to estimate the SE differently\n\n$$ SE(\\bar{X_1} - \\bar{X_2}) = \\sqrt{\\frac{\\hat{\\sigma_1^2}}{N_1} + \\frac{\\hat{\\sigma_2^2}}{N_2}} $$\n\nDegrees of Freedom is also very different:\n\n![](/images/welch_df.png){fig-align=\"center\" width=\"380\"}\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R\n\nWe use the same function as before, but specify that the variances are not equal\n\n```{r}\nindependentSamplesTTest(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n------------------------------------------------------------------------\n\n### Welch's t-test: In R (classic)\n\nLet's then try it out using the traditional `t.test()` function...turns out it is pretty straightforward\n\n```{r}\nt.test(\n  formula = Sleep_Hours_Schoolnight ~ Region, \n  data = state_school, \n  var.equal = FALSE\n)\n```\n\n------------------------------------------------------------------------\n\n## Cool Visualizations\n\nThe library [ggstatsplot](https://indrajeetpatil.github.io/ggstatsplot/) has some wonderful visualizations of various tests\n\n```{r}\n#| code-fold: true\nggstatsplot::ggbetweenstats(\n  data  = state_school,\n  x     = Region,\n  y     = Sleep_Hours_Schoolnight,\n  title = \"Distribution of hours of sleep across Region\"\n)\n```\n\n# In-Class Lab\n\nTake a look at the data in `state_school` and identify another Independent Samples t-test that you can perform\n\n::: nonincremental\n-   Be sure to select (1) a grouping variable and (2) a continuous variable to look at differences between the groups\n:::\n\nFollow the steps that we went through today:\n\n::: nonincremental\n1.  Check for Normality of the variable\n2.  Check for Homogeneity of Variances\n3.  Perform the appropriate t-test\n4.  Report Results\n:::\n\n**Knit the document**\n\n------------------------------------------------------------------------\n\n## Next Time...\n\nPaired Samples t-test\n\n# Paired Samples t-Test in R\n\n[Chapter 13.5 - Learning Stats with R](https://learningstatisticswithr.com/book/ttest.html#pairedsamplesttest)\n\nAlso called \"Dependent Samples t-test\"\n\n-   We have been testing means between two *independent* samples. Participants may be randomly assigned to the separate groups\n\n    -   This is limited to those types of study designs, but what if we have repeated measures?\n\n-   We will then need to compare scores across people...the samples we are comparing now *depend* on one another and are *paired*\n\n------------------------------------------------------------------------\n\n# Common Mistakes and Pitfalls\n\n-   **Misinterpreting p-Values**\n\n-   **Violations of Assumptions**\n\n-   **Sample Size Considerations**\n\n-   **Multiple Testing Issues**\n\n------------------------------------------------------------------------\n\n## Next time...\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"07_ComparingMeans.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.433","auto-stretch":true,"editor":"visual","title":"Comparing Means: t-tests","subtitle":"PSYC 640 - Fall 2023","author":"Dustin Haraden, PhD","editor_options":{"chunk_output_type":"console"},"multiplex":true,"slideNumber":true,"touch":true,"theme":"dark"}}},"projectFormats":["html"]}