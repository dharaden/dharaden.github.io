---
title: "Intro to RMarkdown (and some regression stuff)"
subtitle: "PSYC 640 - Fall 2023"
author: "Dustin Haraden, PhD"
format: 
  revealjs:
    multiplex: true
    scrollable: true
    slide-number: true
    incremental: false
    touch: true
    code-overflow: wrap
    highlightLines: true
    theme: dark
execute: 
  echo: true
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r, include = F}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Overview

Next couple of classes will be split between group work and R Markdown fancifulness

Presentations will start on Wednesday 12/6

Peer Review of Data analytic plan will be assigned tomorrow (how quickly can this be done?)

What are other things we can do? Or questions you have?

## Last Time

::: nonincremental
-   Multiple Regression
-   Group work stuff
:::

------------------------------------------------------------------------

## Today...

-   Review the regression stuff

-   RMarkdown!

    -   Even though we've been doing it this whole time

```{r, results = 'hide', message = F, warning = F}
options(scipen=999)
library(car) #recode conflict with tidyverse
library(tidyverse)
library(psych)
library(easystats)
library(sjPlot)
library(janitor)
```

------------------------------------------------------------------------

### Data for Today

```{r}

student_perf <- read_csv("https://raw.githubusercontent.com/dharaden/psyc640/main/data/Multiple_reg/Student_Performance.csv") %>% 
  clean_names()
```

This data is taken from [Kaggle](https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression) and is simulated data to explore multiple linear regression. Variables include:

::: columns
::: {.column width="50%"}
-   Scores from previous test

-   Average sleep hours

-   Average hours studied
:::

::: {.column width="50%"}
-   Participating in Extracurriculars

-   \# of Practice Questions used

-   Performance Index (**Outcome**)
:::
:::

------------------------------------------------------------------------

# Multiple Regression

## Regression Equation

Going from this:

$$
\hat{Y} = b_0 + b_1X1
$$

. . .

To this

$$
\hat{Y} = b_0 + b_1X_1 + b_2X_2 + ... + b_kX_k
$$

. . .

Regression coefficient values are now "partial" - Represents the contribution to all of outcome ($\hat{Y}$) from *unique* aspects of each $X$

------------------------------------------------------------------------

## 

### Example - Single Predictor ([`tab_model()`](https://strengejacke.github.io/sjPlot/reference/tab_model.html))

Can customize the tables which we will focus more on in the next section

```{r}
fit1 <- lm(performance_index ~ hours_studied, 
           data = student_perf)

summary(fit1)
sjPlot::tab_model(fit1, show.std = TRUE, 
                  title = "Figure 1", 
                  pred.labels = c("Int.", "Hours Studied"), 
                  dv.labels = "Performance Index")
```

------------------------------------------------------------------------

### Single Predictor - Visualizing

```{r}
student_perf %>% 
  ggplot(aes(x = hours_studied, 
             y = performance_index)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

------------------------------------------------------------------------

### Single Predictor- Reporting

```{r}
report(fit1)
```

------------------------------------------------------------------------

### Multiple Predictors - Example

Now let's add in some other variables that we think may contribute to a student's "Performance Index"

```{r}
fit2 <- lm(performance_index ~ hours_studied + sleep_hours + previous_scores, 
           data = student_perf)

summary(fit2)
```

------------------------------------------------------------------------

## Interpreting Coefficients

$$ \hat{Y} = b_0 + b_1X_1 + b_2X_2 + ... + b_kX_k $$

-   Focus on a specific predictor (e.g., $X_1$)

-   For every 1 unit change in $X_1$, there is a $b_1$ unit change in $Y$, [**holding all other predictors constant**]{style="color:red"}

**Note**: Properties of OLS still hold true

-   The sum of residuals will be 0

-   Each predictor ($X$) will be uncorrelated with the residuals

------------------------------------------------------------------------

## Holding Constant??? Wut

```{r}
tab_model(fit2)
```

------------------------------------------------------------------------

## Reporting the results

```{r}
report(fit2)
```

## Creating the Model

There can be many different ways in which we create and compare models with multiple predictors

::: incremental
-   **Simultaneous**: Enter all variables in the model at once
    -   Usually the most conservative and defensible approach (unless there is theory to support a hierarchical approach)
-   **Hierarchically**: Building a sequence of models where a single variable is included/excluded at each step
    -   This is **hierarchical/stepwise regression.** Different from HLM (Hierarchical Linear Modeling)
:::

------------------------------------------------------------------------

## Model Selection ([LSR 15.10](https://learningstatisticswithr.com/book/regression.html#modelselreg))

How can we tell if one model is "better" than the other (it explains more variance in outcome)?

-   Each predictor (or set of predictors) is investigated as to what it adds to the model when it is entered
-   The order of the variables depends on an *a priori* hypothesis

The concept is to ask how much variance is unexplained by our model. The leftovers can be compared to an alternate model to see if the new variable adds anything or if we should focus on **parsimony**

# Model Diagnostics

------------------------------------------------------------------------

## Checking the model ([LSR 15.9](https://learningstatisticswithr.com/book/regression.html#regressiondiagnostics))

Whenever we are looking at the regression model diagnostics, we are often considering the residual values. The types of residuals we can look at are:

::: incremental
-   Ordinary Residuals - Raw

-   Standardized Residuals

-   Studentized Residuals - Takes into account what the SD *would* have been with the removal of the $i$th observation
:::

------------------------------------------------------------------------

### Model Checks - Outlier

We tend to look for various things that may impact our results through the lens of residuals

**1) Outliers** - variables with high Studentized Residuals

![](/images/outlier.PNG){fig-align="center"}

------------------------------------------------------------------------

### Model Checks - Leverage

We tend to look for various things that may impact our results through the lens of residuals

**2) Leverage** - variable is different in all ways from others (not just residuals)

![](/images/leverage.PNG){fig-align="center"}

------------------------------------------------------------------------

### Model Checks - Influence

We tend to look for various things that may impact our results through the lens of residuals

**3) Influence** - outlier with high leverage (*Cook's Distance*)

![](/images/influence.PNG){fig-align="center"}

------------------------------------------------------------------------

### Model Checks - Plots

```{r}
#Cook's Distance
plot(fit2, which = 4)
```

------------------------------------------------------------------------

## Checking Collinearity

We need to check to see if our predictor variables are too highly correlated with each other

To do so we use ***variance inflation factors (VIF)***

-   There will be a VIF that is associated with each predictor in the model
-   Interpreting VIF ([link](https://www.statisticshowto.com/variance-inflation-factor/)) - Starts at 1 and goes up
    -   1 = Not Correlated
    -   1-5 = Moderately Correlated
    -   5+ = Highly Correlated

```{r}
car::vif(fit2)
```

# RMarkdown

------------------------------------------------------------------------

## RMarkdown

This is something that we have been using this whole time!

The script that we use allows us to embed both regular text and code all into a single document. This is what we use for the labs with various levels of success when it comes to `knitting` the document

We'll be spending more time exploring all the cool things that RMarkdown can do

------------------------------------------------------------------------

## Some Useful Resources

[R Markdown: The Definitive Guide](https://bookdown.org/yihui/rmarkdown/)

[R Markdown Cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/rmarkdown-2.0.pdf)

[R Markdown Cookbook](https://bookdown.org/yihui/rmarkdown-cookbook/)

[Custom Formats for R Markdown](https://posit.co/blog/r-markdown-custom-formats/)

------------------------------------------------------------------------

## Ideas for topics to Highlight

-   Making sure we can have things knit

-   [HTML Templates](https://github.com/juba/rmdformats)

-   Code Chunk Options ([Cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/rmarkdown-2.0.pdf))

-   [Fun things to do with HTML Output](https://bookdown.org/yihui/rmarkdown/html-document.html)
